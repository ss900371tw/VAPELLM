import streamlit as st
import requests
import tempfile
import os
import shutil
import time
import random
import re
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from PIL import Image
from googleapiclient.discovery import build
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from urllib.parse import urljoin
import pickle
from googleapiclient.discovery import build
from PIL import Image
from io import BytesIO
from langchain_core.messages import AIMessage
from playwright.sync_api import sync_playwright
import sys
from urllib.parse import urlparse
from playwright.sync_api import sync_playwright
from urllib.parse import urlparse
import pickle
from bs4 import BeautifulSoup
import requests
import time
import sys
from bs4 import BeautifulSoup
import time
import undetected_chromedriver as uc
from serpapi import GoogleSearch


load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY","")



# -------------------- 2. Prompt --------------------
text_template = """
ä½œç‚ºä¸€ä½å°ˆæ¥­çš„é›»å­è¸äº¤æ˜“ç¶²ç«™åˆ†é¡å™¨ï¼Œ
ä½ å…·å‚™è¾¨è­˜ä¸‹åˆ— HTML å…§å®¹ä¸¦å°‡å…¶åˆ†é¡çš„èƒ½åŠ›ï¼š

è«‹ä¾æ“šä»¥ä¸‹å…©é¡é€²è¡Œåˆ†é¡ï¼š

(1) é›»å­è¸éŠ·å”®ç¶²ç«™

(2) éæ­¤é¡ç¶²ç«™

ç”±æ–¼ç”¢å“åç¨±ã€å“ç‰Œæˆ–æåŠæ–¹å¼ç„¡çª®ç„¡ç›¡ï¼Œè«‹å‹¿åƒ…ä¾è³´ç‰¹å®šé—œéµå­—ï¼Œ
è€Œæ‡‰æ ¹æ“šé€šç”¨æŒ‡æ¨™åˆ¤æ–·ï¼Œç‰¹åˆ¥æ³¨æ„ä»¥ä¸‹å¹¾é»ï¼š

1ï¼‰ä½¿ç”¨æƒ…å¢ƒæˆ–å®£ç¨±å…§å®¹
è«‹ç•™æ„æ˜¯å¦æœ‰æ˜ç¤ºæˆ–æš—ç¤ºæ”¹è®Šæƒ…ç·’ã€ç·©è§£å£“åŠ›ã€æå‡å°ˆæ³¨ã€åŠ©çœ ã€æ”¾é¬†èº«å¿ƒç­‰æ•ˆæœçš„æè¿°ã€‚
è‹¥ç”¢å“å®£ç¨±å…·å‚™éä¸€èˆ¬æ€§å¨›æ¨‚æˆ–å¥åº·åŠŸæ•ˆï¼ˆä¾‹å¦‚ï¼šã€Œå¼·åŠ›æ”¾é¬†ã€ã€ã€Œè¶…å¿«æ„Ÿã€ã€ã€ŒåŠ©çœ ç¥å™¨ã€ã€ã€Œå·¥ä½œæç¥ã€ç­‰ï¼‰ï¼Œå¯èƒ½æš—ç¤ºè©²é›»å­è¸æˆ–ç…™æ²¹ç”¢å“å«æœ‰ç‰¹æ®Šæ·»åŠ ç‰©ï¼Œé ˆé€²ä¸€æ­¥é—œæ³¨å…¶åˆæ³•æ€§èˆ‡æˆåˆ†ä¾†æºã€‚
é›»å­è¸è£ç½®èˆ‡ç…™æ²¹ï¼ˆe-liquidï¼‰è‹¥æ­é…æ­¤é¡å®£ç¨±ï¼Œä¹Ÿæ‡‰è¦–ç‚ºé›»å­è¸éŠ·å”®ç¶²ç«™çš„ä¸€éƒ¨åˆ†ã€‚


2ï¼‰äº¤æ˜“æ€§ç·šç´¢
æåŠåƒ¹æ ¼ã€åƒæ˜¯ã€Œç§è¨Šæˆ‘ã€ã€ã€Œç¥•å¯†é…æ–¹ã€ã€ã€ŒåŠ  LINE è©³è«‡ã€ã€ã€Œéš±å¯†å‡ºè²¨ã€ã€ã€ŒDM æˆ‘ã€ã€ã€ŒPM æˆ‘ã€ç­‰æªè¾­ï¼Œ
å¯èƒ½èˆ‡éæ³•æˆ–å—é™ç”¢å“æœ‰é—œã€‚
è‹¥ç¶²ç«™æä¾›ï¼š
åŠ å…¥è³¼ç‰©è»Š
å¿«é€Ÿä¸‹å–®
ç”¢å“å‹éŒ„ç€è¦½
â†’ å³ä¾¿è¡¨é¢åˆæ³•ï¼Œä¹Ÿæ‡‰æé«˜è­¦è¦ºï¼Œå¯èƒ½å±¬æ–¼éæ³•è²©å”®ç¶²ç«™ã€‚
â†’ å°æ–¼æ¨¡ç³Šä¸æ¸…æˆ–è‡ªç›¸çŸ›ç›¾çš„è²æ˜ä¹Ÿè¦ä¿æŒè­¦æƒ•ã€‚
âš ï¸ æ³¨æ„ï¼šå°ˆæ¥­å¤–è§€èˆ‡ç§‘å­¸ç”¨èªç„¡æ³•æ©è“‹å…¶éŠ·å”®ç®¡åˆ¶ç‰©è³ªçš„äº‹å¯¦ã€‚


3ï¼‰è³‡è¨Šæ€§æˆ–æ•™è‚²æ€§ç¶²ç«™
è‹¥ç¶²ç«™çš„å…§å®¹åƒ…é™æ–¼å¥åº·çŸ¥è­˜ã€é†«ç™‚åƒè€ƒã€å…¬å…±è¡›ç”Ÿå®£å°ï¼Œ
è€Œæœªæä¾›ä»»ä½•ç”¢å“è³¼è²·ã€åƒ¹æ ¼ã€è¯çµ¡æ–¹å¼æˆ–ä¸‹å–®åŠŸèƒ½ï¼Œæ‡‰åˆ†é¡ç‚º(2) éæ­¤é¡ç¶²ç«™ã€‚

é€™é¡ç¶²ç«™å¯èƒ½åŒ…å«ï¼š
å¥åº·ç™¾ç§‘å…¨æ›¸ï¼ˆå¦‚ï¼šWebMDã€NIHã€Mayo Clinicï¼‰
é†«ç™‚æˆ–è—¥å“è³‡æ–™åº«ï¼ˆå¦‚ï¼šdrugs.comï¼‰
æ”¿åºœæ©Ÿæ§‹ç¶²ç«™æˆ–éç‡Ÿåˆ©å¥åº·å¹³å°
æ¢è¨é›»å­è¸å°å¥åº·å½±éŸ¿ã€æˆåˆ†åˆ†æã€æˆ’è¸å»ºè­°çš„ç§‘æ™®æ–‡ç« 
å³ä½¿ç¶²ç«™ä¸­æåŠé›»å­è¸å“ç‰Œã€æˆåˆ†æˆ–è£ç½®ä»‹ç´¹ï¼Œåªè¦æœªæ¶‰åŠè²©å”®è¡Œç‚ºã€è³¼ç‰©åŠŸèƒ½ã€åƒ¹æ ¼è³‡è¨Šæˆ–è¯çµ¡ä¸‹å–®å¼•å°ï¼Œå³æ‡‰æ­¸ç‚ºè³‡è¨Šæ€§ç”¨é€”ã€‚
ğŸ§  ç‰¹åˆ¥æ³¨æ„ï¼šè«‹å‹¿éŒ¯åˆ¤æ•™è‚²æ€§ç¶²ç«™ç‚ºè²©å”®ç¶²ç«™ã€‚

ğŸ”ã€å¾…åˆ†é¡ HTML å…§å®¹ã€‘ï¼š

{html}

ğŸ“‹ ç¶œåˆå ±å‘Šï¼š
æœ€çµ‚åˆ†é¡ï¼š(1) é›»å­è¸éŠ·å”®ç¶²ç«™  æˆ– (2) éæ­¤é¡ç¶²ç«™

å°è‡´æ­¤åˆ†é¡çš„é€šç”¨åˆ¤æ–·ä¾æ“šï¼ˆæ ¹æ“šä¸Šé¢ 1ï½3 æ¢ï¼‰

è‹¥æœ‰ä»»ä½•æ¨¡ç³Šè™•ï¼ˆä¾‹å¦‚çœ‹èµ·ä¾†å¾ˆå°ˆæ¥­ä½†å…¶å¯¦æœ‰è²©å”®è¡Œç‚ºï¼‰ï¼Œè«‹èªªæ˜ä½ çš„è™•ç†æ–¹å¼ã€‚


"""
prompt = PromptTemplate.from_template(template=text_template)

# -------------------- 3. çˆ¬å–ç¶²é æ–‡å­— --------------------


import subprocess
import os

# ç¢ºä¿ç€è¦½å™¨å·²å®‰è£ï¼ˆåƒ…é¦–æ¬¡éƒ¨ç½²æœƒè§¸ç™¼ï¼‰
def ensure_playwright_browser():
    chromium_path = os.path.expanduser("~/.cache/ms-playwright/chromium-*/chrome-linux/chrome")
    if not os.path.exists(chromium_path):
        try:
            print("âš™ï¸ å®‰è£ Playwright ç€è¦½å™¨ä¸­...")
            subprocess.run(["playwright", "install", "chromium"], check=True)
        except Exception as e:
            print("âŒ Playwright å®‰è£å¤±æ•—:", e)

ensure_playwright_browser()

from urllib.parse import urlparse
import pickle
import time
from bs4 import BeautifulSoup
import requests
from requests_html import HTMLSession

from playwright.sync_api import sync_playwright
from urllib.parse import urlparse
import pickle
from bs4 import BeautifulSoup
import requests
import time

from playwright.sync_api import sync_playwright
from urllib.parse import urlparse
import pickle
from bs4 import BeautifulSoup
import requests
import time



import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import pickle
import asyncio
from playwright.async_api import async_playwright


import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import pickle
import time
import undetected_chromedriver as uc  # âœ… ä¿ç•™é€™å€‹ï¼Œä¸ä½¿ç”¨ä¹Ÿä¸åˆªé™¤
import asyncio
from playwright.async_api import async_playwright


from bs4 import BeautifulSoup
import requests
import pickle
import time
from urllib.parse import urlparse
from playwright.sync_api import sync_playwright


import requests
from bs4 import BeautifulSoup
import pickle
import time
from urllib.parse import urlparse
from playwright.sync_api import sync_playwright
import undetected_chromedriver as uc

import os
import requests
import pickle
import time
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from playwright.sync_api import sync_playwright
import undetected_chromedriver as uc

from playwright.sync_api import sync_playwright
from urllib.parse import urlparse
import pickle
from bs4 import BeautifulSoup
import requests



import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup

import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup

from bs4 import BeautifulSoup
from urllib.parse import urlparse
import undetected_chromedriver as uc
import pickle
import time


import undetected_chromedriver as uc
import time
import pickle

import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import os

import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import os

# save_cookie.py
import asyncio
from playwright.async_api import async_playwright
import pickle
import os

from seleniumbase import SB
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import pickle
import time
from playwright.sync_api import sync_playwright

import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from playwright.sync_api import sync_playwright
import pickle
import os



def crawl_all_text(url: str, cookie_file: str = "cookies.pkl"):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        return soup.get_text(separator="\n", strip=True)

    except requests.exceptions.RequestException as e:
        if "403" in str(e):
            print("âš ï¸ HTTP 403 Forbidden - åˆ‡æ›ç‚º Playwright ç¹éé©—è­‰")

            try:
                with sync_playwright() as p:
                    browser = p.chromium.launch(headless=False)  # å»ºè­° debug æ™‚å…ˆç”¨é headless
                    context = browser.new_context()

                    parsed = urlparse(url)
                    base_url = f"{parsed.scheme}://{parsed.netloc}/"

                    # å…ˆé–‹é¦–é ï¼Œå»ºç«‹ domain context
                    page = context.new_page()
                    page.goto(base_url, timeout=30000)
                    time.sleep(3)

                    # è¼‰å…¥ cookiesï¼ˆå¦‚æœ‰ï¼‰
                    try:
                        with open(cookie_file, "rb") as f:
                            cookies = pickle.load(f)
                            for cookie in cookies:
                                if 'domain' not in cookie:
                                    cookie['domain'] = "." + parsed.hostname
                            context.add_cookies(cookies)
                    except Exception as err:
                        print("âš ï¸ Cookie è¼‰å…¥å¤±æ•—:", err)

                    # è·³è½‰åˆ°ç›®æ¨™é é¢
                    page.goto(url, timeout=30000)
                    time.sleep(5)
                    html = page.content()
                    browser.close()

                    soup = BeautifulSoup(html, "html.parser")
                    for tag in soup(["script", "style"]):
                        tag.decompose()

                    body_text = soup.get_text(separator="\n", strip=True)
                    if "é©—è­‰æ‚¨æ˜¯äººé¡" in body_text or "Enable JavaScript and cookies to continue" in body_text:
                        return "[âš ï¸ Cloudflare Verification Failed] Cookie å¯èƒ½å¤±æ•ˆæˆ–æœªæ­£ç¢ºé™„åŠ "

                    return body_text

            except Exception as e:
                return f"{url}"



# ---------------------------------------------------------------------------
# 4. çˆ¬å–ç¶²é çš„åœ–ç‰‡ URL
# ---------------------------------------------------------------------------
def upload_image_to_imgbb(image_path):
    with open(image_path, "rb") as f:
        IMGBB_API_KEY = os.getenv("IMGBB_API_KEY")
        res = requests.post(
            "https://api.imgbb.com/1/upload",
            params={"key": IMGBB_API_KEY},
            files={"image": f}
        )
    res.raise_for_status()
    return res.json()["data"]["url"]


def search_similar_images_via_serpapi(image_url):
    SERPAPI_API_KEY = os.getenv("SERPAPI_API_KEY")
    params = {
        "engine": "google_reverse_image",
        "api_key": SERPAPI_API_KEY,
        "image_url": image_url,
    }

    search = GoogleSearch(params)
    results = search.get_dict()

    st.markdown("<h3 style='color:white;'>ğŸ“¦ SerpAPI å›å‚³å…§å®¹</h3>", unsafe_allow_html=True)
    st.json(results)

    image_results = results.get("image_results", [])
    urls = [item.get("link") for item in image_results if "link" in item]
    return urls

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

def is_image_url(url: str) -> bool:
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                          "AppleWebKit/537.36 (KHTML, like Gecko) "
                          "Chrome/114.0.0.0 Safari/537.36"
        }
        resp = requests.head(url, headers=headers, timeout=5, allow_redirects=True)
        return resp.headers.get("Content-Type", "").lower().startswith("image/")
    except:
        return False

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from io import BytesIO
from PIL import Image


import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse, parse_qs, unquote
from io import BytesIO
from PIL import Image
import os
import shutil
import requests
from urllib.parse import urlparse, parse_qs, unquote, urljoin
from bs4 import BeautifulSoup
from PIL import Image
from io import BytesIO

from IPython.display import display, Image as IPyImage  # ç”¨æ–¼ Jupyter é¡¯ç¤ºåœ–ç‰‡

# --- å¾ Next.js å„ªåŒ–ç¶²å€å–å‡ºåŸåœ– ---
def extract_real_image_url(next_image_url: str) -> str:
    try:
        query = urlparse(next_image_url).query
        params = parse_qs(query)
        real_url = params.get("url", [""])[0]
        return unquote(real_url)
    except:
        return next_image_url

# --- è¦ç¯„åŒ– src ---
def normalize_src(src: str, base_url: str) -> str:
    if not src:
        return ""
    if src.startswith("//"):
        return "https:" + src
    return urljoin(base_url, src)

# --- çˆ¬åœ–ç‰‡ ---
def crawl_images(url: str, max_images=2):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/114.0.0.0 Safari/537.36",
        "Referer": url
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        img_tags = soup.find_all("img")

        results = []
        seen = set()

        for img in img_tags:
            src_candidates = [
                img.get("src"),
                img.get("data-src"),
                img.get("data-original"),
                img.get("data-image"),
                img.get("data-lazy"),
            ]

            for raw_src in src_candidates:
                img_url = normalize_src(raw_src, url)
                if not img_url or "base64" in img_url or img_url in seen:
                    continue
                seen.add(img_url)

                if "_next/image" in img_url and "url=" in img_url:
                    img_url = extract_real_image_url(img_url)

                try:
                    img_resp = requests.get(img_url, headers=headers, timeout=5)
                    img_resp.raise_for_status()
                    img = Image.open(BytesIO(img_resp.content)).convert("RGB")

                    img_io = BytesIO()
                    img.save(img_io, format="PNG")
                    img_io.seek(0)

                    results.append((img_io, img_url))
                    break

                except Exception as e:
                    continue

            if len(results) >= max_images:
                break

        return results

    except Exception as e:
        print(f"âŒ crawl_images ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []




# -------------------- 6. åˆ†æåœ–ç‰‡ --------------------
def get_image_prompt(img_url: str) -> str:
    return f"""
è«‹å”åŠ©æˆ‘åˆ†æé€™å¼µåœ–ç‰‡ï¼š{img_url}

âœ… è«‹å®Œæˆä»¥ä¸‹ä»»å‹™ï¼š

1. **æè¿°åœ–ç‰‡çš„æ•´é«”å…§å®¹èˆ‡æ§‹åœ–**ï¼ˆåŒ…å«å‡ºç¾çš„ç‰©å“ã€äººç‰©ã€èƒŒæ™¯ã€å‹•ä½œã€æ–‡å­—ç­‰ï¼‰ã€‚
2. æ ¹æ“šä¸‹åˆ—åˆ†é¡ï¼Œé€ä¸€æª¢æŸ¥åœ–ç‰‡ä¸­æ˜¯å¦å‡ºç¾ç›¸é—œé …ç›®ï¼Œä¸¦èªªæ˜åŸå› èˆ‡åˆ¤æ–·ä¾æ“šã€‚
3. è‹¥åœ–ç‰‡ä¸­æŸé …ç›®ã€Œå¯èƒ½å‡ºç¾ä½†ä¸ç¢ºå®šã€ï¼Œè«‹èªªæ˜ç‚ºä½•ä¸ç¢ºå®šã€‚
4. æœ€å¾Œè«‹ç¸½çµåˆ¤å®šçµæœï¼Œä¸¦æ˜ç¢ºèªªæ˜æ˜¯å¦å±¬æ–¼é«˜é¢¨éšªåœ–ç‰‡ï¼ˆåŒ…å«å—é™é …ç›®ï¼‰ã€‚

ğŸ“‹ å—é™é …ç›®åˆ†é¡å¦‚ä¸‹ï¼š

**a. é›»å­è¸è£ç½®æˆ–é›¶ä»¶**  
å¦‚ä¸»æ©Ÿã€æœ¬é«”ã€é›»æ± å¡åŒ£ã€éœ§åŒ–å™¨ã€å¸å˜´ã€å……é›»å™¨ç­‰ã€‚

**b. é›»å­è¸å“ç‰Œèˆ‡æ¨™èªŒ**  
å¦‚ JUULã€RELXã€MYLE ç­‰å•†æ¨™ã€æ–‡å­—æ¨™èªŒæˆ– LOGOã€‚

**c. å¸ç…™æˆ–éœ§æ°£æ•ˆæœ**  
åœ–ä¸­æ˜¯å¦æœ‰æ˜é¡¯ç…™éœ§ã€è’¸æ°£æˆ–éœ§æ°£æ“´æ•£æ•ˆæœã€‚

**d. é›»å­è¸æ–‡åŒ–ç›¸é—œå…ƒç´ **  
å¦‚ vape èšæœƒã€ç…™åœˆè¡¨æ¼”ï¼ˆO-ringsï¼‰ã€ç›¸é—œå¡—é´‰ã€ç©¿è‘—å°èŠ±æœé£¾ç­‰ã€‚

**e. æ¨å»£è¡ŒéŠ·å…§å®¹**  
å¦‚ä¿ƒéŠ·æ¨™èªã€åƒ¹æ ¼è³‡è¨Šã€è³¼è²·é€£çµã€å„ªæƒ ç¢¼ã€è³¼ç‰©è»Šç­‰å°è³¼è¨Šæ¯ã€‚

ğŸ“ å›è¦†ç¯„ä¾‹æ ¼å¼ï¼š
- åœ–ç‰‡æè¿°ï¼šXXX
- a. é›»å­è¸è£ç½®ï¼šæœ‰/ç„¡ï¼Œåˆ¤æ–·ä¾æ“šæ˜¯â€¦
- b. å“ç‰Œèˆ‡æ¨™èªŒï¼šâ€¦
- c. éœ§æ°£æ•ˆæœï¼šâ€¦
- d. æ–‡åŒ–å…ƒç´ ï¼šâ€¦
- e. è¡ŒéŠ·å…§å®¹ï¼šâ€¦
- ç¸½çµåˆ¤å®šï¼šâœ… Safe / ğŸš¨ Warningï¼ˆä¸¦èªªæ˜åŸå› ï¼‰

ğŸ“· è«‹ä¾ç…§ä»¥ä¸Šæ ¼å¼ï¼Œè©³ç´°èªªæ˜åœ–ç‰‡å…§å®¹èˆ‡åˆ¤æ–·éç¨‹ã€‚
"""

from openai import OpenAI
from openai.types.chat import ChatCompletionMessage
from io import BytesIO
import base64

import requests
from io import BytesIO
import base64


from langchain.schema.messages import HumanMessage
from io import BytesIO

def classify_image(image_input, model):
    """
    image_input å¯ä»¥æ˜¯ï¼š
    - åœ–ç‰‡ç¶²å€ (str)
    - BytesIO åœ–ç‰‡è³‡æ–™ï¼ˆç›®å‰ä¸æ”¯æ´ï¼‰
    - æœ¬åœ°æª”æ¡ˆè·¯å¾‘ (str)ï¼ˆæœªä¾†æ“´å……ï¼‰

    model: ChatOpenAI é¡å‹æ¨¡å‹ï¼ˆå¦‚ gpt-4-vision-previewï¼‰
    """
    try:
        # ğŸŒ å¦‚æœæ˜¯åœ–ç‰‡ç¶²å€ï¼ˆæ¨è–¦æ–¹å¼ï¼‰
        if isinstance(image_input, str) and image_input.startswith("http"):
            message = HumanMessage(
                content=[
                    {"type": "text", "text": "è«‹åˆ¤æ–·é€™å¼µåœ–ç‰‡æ˜¯å¦åŒ…å«é›»å­è¸ã€æ¯’å“æˆ–ç›¸é—œç¬¦è™Ÿï¼Œå›å‚³ï¼šğŸš¨ Warning æˆ– âœ… Safe"},
                    {"type": "image_url", "image_url": {"url": image_input}},
                ]
            )
            result = model.invoke([message])
            return result.content

        # ğŸš« BytesIO ä¸æ”¯æ´ï¼ˆOpenAI SDK æ‰èƒ½è™•ç†ï¼‰
        elif isinstance(image_input, BytesIO):
            return "âŒ BytesIO è¼¸å…¥å°šä¸æ”¯æ´ï¼Œè«‹å…ˆä¸Šå‚³åˆ°åœ–åºŠå–å¾—ç¶²å€å¾Œå†åˆ¤æ–·"

        # ğŸ§¯ å…¶ä»–é¡å‹éŒ¯èª¤
        else:
            return f"âŒ ä¸æ”¯æ´çš„åœ–ç‰‡è¼¸å…¥é¡å‹ï¼ˆæ”¶åˆ°é¡å‹ï¼š{type(image_input)}ï¼‰"

    except Exception as e:
        return f"âš ï¸ åœ–ç‰‡åˆ†æå¤±æ•—ï¼š{e}"


from langchain.schema.messages import HumanMessage
from io import BytesIO

def classify_image(image_input, model):
    """
    image_input å¯ä»¥æ˜¯ï¼š
    - åœ–ç‰‡ç¶²å€ (str)
    - BytesIO åœ–ç‰‡è³‡æ–™ï¼ˆç›®å‰ä¸æ”¯æ´ï¼‰
    - æœ¬åœ°æª”æ¡ˆè·¯å¾‘ (str)ï¼ˆæœªä¾†æ“´å……ï¼‰

    model: ChatOpenAI é¡å‹æ¨¡å‹ï¼ˆå¦‚ gpt-4-vision-previewï¼‰
    """
    try:
        # ğŸŒ å¦‚æœæ˜¯åœ–ç‰‡ç¶²å€ï¼ˆæ¨è–¦æ–¹å¼ï¼‰
        if isinstance(image_input, str) and image_input.startswith("http"):
            message = HumanMessage(
                content=[
                    {"type": "text", "text": "è«‹åˆ¤æ–·é€™å¼µåœ–ç‰‡æ˜¯å¦åŒ…å«é›»å­è¸ã€æ¯’å“æˆ–ç›¸é—œç¬¦è™Ÿï¼Œå›å‚³ï¼šğŸš¨ Warning æˆ– âœ… Safe"},
                    {"type": "image_url", "image_url": {"url": image_input}},
                ]
            )
            result = model.invoke([message])
            return result.content

        # ğŸš« BytesIO ä¸æ”¯æ´ï¼ˆOpenAI SDK æ‰èƒ½è™•ç†ï¼‰
        elif isinstance(image_input, BytesIO):
            return "âŒ BytesIO è¼¸å…¥å°šä¸æ”¯æ´ï¼Œè«‹å…ˆä¸Šå‚³åˆ°åœ–åºŠå–å¾—ç¶²å€å¾Œå†åˆ¤æ–·"

        # ğŸ§¯ å…¶ä»–é¡å‹éŒ¯èª¤
        else:
            return f"âŒ ä¸æ”¯æ´çš„åœ–ç‰‡è¼¸å…¥é¡å‹ï¼ˆæ”¶åˆ°é¡å‹ï¼š{type(image_input)}ï¼‰"

    except Exception as e:
        return f"âš ï¸ åœ–ç‰‡åˆ†æå¤±æ•—ï¼š{e}"

# -------------------- 7. Google Search --------------------
def google_search(query, count=10):
    api_key = os.getenv("GOOGLE_API_KEY")
    cx = os.getenv("GOOGLE_CX")
    if not api_key or not cx:
        print("âŒ GOOGLE_API_KEY æˆ– GOOGLE_CX æ²’æœ‰æ­£ç¢ºè¨­å®š")
        return []
    try:
        service = build("customsearch", "v1", developerKey=api_key)
        results = []
        fetched = 0
        while fetched < count:
            num = min(10, count - fetched)
            start = fetched + 1
            res = service.cse().list(q=query, cx=cx, num=num, start=start).execute()
            items = res.get("items", [])
            results.extend([item["link"] for item in items])
            fetched += len(items)
            if len(items) < num:
                break
        return results
    except Exception as e:
        print(f"âŒ Google æœå°‹éŒ¯èª¤ï¼š{e}")
        return []

# -------------------- 8. é»‘åå–® --------------------
blacklist_domains = [
    ".edu", ".gov", ".ac.", ".org", ".wiki", "usask.ca", "su.se", "article",
    "researchgate", "sciencedirect", "osf.io", "digitalcommons",
    "escholarship", "openai.com", "archive.org", "wiktionary",
    "urbandictionary", "dictionary", "bjc-r", "ecprice", "adamrose"
]
blacklist_keywords_in_url = [
    "slang", "street-names", "code-words", "download", "vocab", "wordlist",
    "unigrams", "passphrases", "pdf", "xml", "djvu.txt", "txt", "books",
    "raw/main", "viewcontent.cgi", "novel.pdf", "API/docs", "textfiles",
    "publications"
]

def is_blacklisted_url(url: str) -> bool:
    url_lower = url.lower()
    return any(domain in url_lower for domain in blacklist_domains) or \
           any(kw in url_lower for kw in blacklist_keywords_in_url)
    
# -------------------- 9. Streamlit ä¸»ç¨‹å¼ --------------------
def main():
    st.markdown("<h1 style='text-align:center;color:white;'>é›»å­è¸ç¶²ç«™åµæ¸¬ç³»çµ±</h1>", unsafe_allow_html=True)
    # ä½¿ç”¨ OpenAI GPT-4o æ¨¡å‹


    # èƒŒæ™¯æ¨£å¼èˆ‡ä¸»é¡Œæ–‡å­—
    st.markdown("""
    <style>
        .stApp {
            background-image: url("https://raw.githubusercontent.com/ss900371tw/VAPELLM/refs/heads/main/%E9%9B%BB%E5%AD%90%E8%8F%B8%E7%B6%B2%E7%AB%99%E5%81%B5%E6%B8%AC%E7%B3%BB%E7%B5%B1%20bg.png");
            background-size: cover;
            background-repeat: no-repeat;
            background-attachment: fixed;
        }
        h1, h2, h3 {
            color: #00FFFF;
        }
        .stButton > button {
            background-color: #3EB489;
            color: white;
            font-weight: bold;
            border-radius: 8px;
            padding: 0.5rem 1.2rem;
        }
    </style>
    """, unsafe_allow_html=True)

    st.markdown("""
    <p style='text-align:center; font-size: 24px; color: white;'>ğŸ§  åˆ©ç”¨ OpenAI + åœ–ç‰‡è¾¨è­˜ï¼Œè‡ªå‹•åˆ†é¡é›»å­ç…™ç›¸é—œç¶²ç«™</p>
    """, unsafe_allow_html=True)
    llm_text = ChatOpenAI(api_key=openai_api_key, model="gpt-4o", temperature=0)
    llm_image = ChatOpenAI(api_key=openai_api_key, model="gpt-4.1", temperature=0)
    parser = StrOutputParser()
    chain = prompt | llm_text | parser
    # åˆå§‹åŒ–
    if "selected_mode" not in st.session_state:
        st.session_state.selected_mode = None

    def render_card(icon, title, desc, key):
        selected = st.session_state.get("selected_mode") == title
        border = "4px solid #3EB489" if selected else "1px solid #999999"
        shadow = "0 0 20px #3EB489" if selected else "none"
        bg = "#0c1b2a" if selected else "#1a1f2b"
    
        with st.container():
            st.markdown(f"""
            <style>
            div#{key}_card {{
                background-color: {bg};
                color: white;
                border-radius: 16px;
                border: {border};
                box-shadow: {shadow};
                padding: 1.5rem;
                height: 320px;
                text-align: center;
                transition: all 0.2s ease;
                display: flex;
                flex-direction: column;
                justify-content: space-between;
            }}
            div#{key}_card:hover {{
                transform: scale(1.02);
                box-shadow: 0 0 25px #3EB489;
            }}
            div[data-testid="stButton"] > button#{key}_btn {{
                background-color: #3EB489;
                color: white;
                font-weight: bold;
                border: none;
                border-radius: 6px;
                font-size: 1rem;
                height: 40px;
                padding: 0 1.2rem;
            }}
            </style>
            """, unsafe_allow_html=True)
    
            # âœ… æŠŠæ‰€æœ‰å…§å®¹å¯«åœ¨é€™ä¸€å€‹ HTML block è£¡
            st.markdown(f"""
            <div id="{key}_card">
                <div style="font-size: 2rem;">{icon}</div>
                <div style="font-size: 1.2rem; font-weight: bold;">{title}</div>
                <div style="font-size: 0.9rem; color: #ccc;">{desc}</div>
                <div style="margin-top: 10px;">
            """, unsafe_allow_html=True)
    
            # âœ… Streamlit çš„æŒ‰éˆ•ä¹Ÿæ”¾åœ¨ div è£¡é¢
            if st.button("é¸æ“‡", key=f"{key}_btn"):
                st.session_state.selected_mode = title
                st.rerun()
    
            st.markdown("</div></div>", unsafe_allow_html=True)  # é—œé–‰å…©å±¤ div

    # æ¨¡å¼é¸æ“‡
    st.markdown("""
<style>
.banner-text {
    background-color: #0052cc;  /* æ·±è—è‰² */
    color: white;               /* ç™½å­— */
    font-size: 16px;
    font-weight: bold;
    text-align: center;
    padding: 10px;
    border-radius: 6px;
    margin: 10px 0px;
}
</style>

<div class="banner-text">
è«‹é¸æ“‡åˆ†ææ¨¡å¼
</div>
""", unsafe_allow_html=True)

    if "selected_mode" not in st.session_state:
        st.session_state.selected_mode = None

    # é›†ä¸­è™•ç†æŒ‰éˆ•äº‹ä»¶
    col1, col2, col3 , col4= st.columns(4)
    with col1:
        render_card("ğŸ”", "å–®ç¶²å€åˆ†æ", "åˆ†æå€‹åˆ¥ç¶²ç«™çš„åœ–æ–‡", key="single")
    with col2:
        render_card("ğŸ“‚", "æ‰¹é‡åˆ†æ", "ä¸Šå‚³å¤šç¶²ç«™txtæª”åˆ†æ", key="batch")
    with col3:
        render_card("ğŸŒ", "é—œéµå­—åˆ†æ", "æ ¹æ“šé—œéµå­—çˆ¬èŸ²åˆ†æ", key="search")
    with col4:
        render_card("ğŸ“¸", "ä»¥åœ–åˆ†æ", "ä»¥åœ–æœåœ–ä¸¦çˆ¬èŸ²åˆ†æ", key="picture")
    
    mode = st.session_state.get("selected_mode")
    
    if mode:    
        if "å–®ç¶²å€åˆ†æ" in mode:
            # å»ºç«‹å·¦å³æ’åˆ—æ¬„ä½
            # è‡ªè¨‚æŒ‰éˆ•æ¨£å¼è®“å®ƒè²¼é½Š text_input é«˜åº¦
            
            # CSSï¼šç¾åŒ–æŒ‰éˆ•èˆ‡è¼¸å…¥æ¡†å®¹å™¨
            # --- è‡ªè¨‚æ¨£å¼ ---

            # --- è‡ªè¨‚æ¨£å¼ ---
            st.markdown("""
            <style>
            div[data-testid="column"] div:has(button) {
                display: flex;
                align-items: center;
                justify-content: center;
            }
            div[data-testid="column"] div:has(input) {
                display: flex;
                align-items: center;
            }
            input[type="text"] {
                height: 40px;
                font-size: 16px;
                padding: 6px 10px;
                border-radius: 8px;
                border: 1.5px solid #ccc;
            }
            div[data-testid="column"] button {
                height: 40px;
                width: 60px;
                font-size: 18px;
                background-color: #3EB489;
                color: white;
                border-radius: 10px;
                border: 2px solid #ff5f5f;
                padding: 0;
            }
            </style>
            """, unsafe_allow_html=True)
            
            # --- è¼¸å…¥è¡¨å–®å€å¡Š ---
            with st.form("url_input_form"):
                col1, col2 = st.columns([5, 1])
            
                with col1:
                    url = st.text_input("", placeholder="è«‹è¼¸å…¥ç¶²å€ï¼š", label_visibility="collapsed")
            
                with col2:
                    submitted = st.form_submit_button("ç¢ºå®š")
            
            # --- åˆ†æé‚è¼¯åœ¨è¡¨å–®å¤–åˆ¤æ–·ï¼Œæ‰èƒ½æ­£ç¢ºä¸­æ­¢æµç¨‹ ---
            if submitted:
                if not url.strip():
                    st.markdown("""
                    <div style="
                        background-color: #fff3cd;
                        color: #856404;
                        padding: 1rem;
                        border-radius: 10px;
                        border: 1px solid #ffeeba;
                        font-size: 16px;
                    ">
                    âš ï¸ è«‹è¼¸å…¥æœ‰æ•ˆç¶²å€
                    </div>
                    """, unsafe_allow_html=True)
                    return
                else:
                    st.markdown(f"<h3 style='color:white;'>ğŸ” æ­£åœ¨åˆ†æï¼š<a href='{url}' target='_blank'>{url}</a></h3>", unsafe_allow_html=True)
                    # é€™è£¡å¯ä»¥ç¹¼çºŒæ”¾åˆ†æç¨‹å¼é‚è¼¯

                with st.spinner("â³ æ­£åœ¨è®€å–ç¶²ç«™å…§å®¹èˆ‡åœ–ç‰‡"): 
                    text_content = crawl_all_text(url)
                    text_result = chain.invoke(text_content)
    
                    image_urls = crawl_images(url)
                    flagged_images = 0
    
                    # åˆ†æˆå…©æ¬„é¡¯ç¤ºåˆ†æçµæœ
                    col1,  col2 = st.columns([5,  5])
    
                    with col1:
                        st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #1f77b4;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“„ æ–‡å­—åˆ†é¡çµæœ</h4>
        <pre style="white-space:pre-wrap;font-size:0.92rem;font-family:inherit;">
    {text_result} 
        </pre>
    </div>
    """, unsafe_allow_html=True)
                    with col2:
                        if not image_urls:
                            st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
        <div style="font-size:0.9rem;"><b>(æœªæ‰¾åˆ°åœ–ç‰‡)</b></div>
    </div>
    """, unsafe_allow_html=True)
                        else:
                            sample_size = min(2, len(image_urls))
                            for img in random.sample(image_urls, sample_size):
                                img_result = classify_image(img, llm_image)
                                st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
        <img src="{img}" style="max-width:100%;border-radius:8px;margin-bottom:0.5rem;">
        <div style="font-size:0.9rem;"><b>åˆ†é¡çµæœï¼š</b>{img_result}</div>
    </div>""", unsafe_allow_html=True)
                                if "Warning" in img_result:
                                    flagged_images += 1
    
    
    
                st.markdown("---")
                st.markdown("<h3 style='color:white;'>ğŸ“‹ ç¶œåˆçµè«–</h3>", unsafe_allow_html=True)
                if "(1)" in text_result and flagged_images > 0:
                    st.markdown("""
<div style="
    background-color: #fff3cd;
    color: #856404;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #ffeeba;
    font-size: 16px;
">
âš ï¸ <strong>é«˜é¢¨éšªç¶²ç«™</strong>ï¼šç¶²ç«™å¯èƒ½æ¶‰åŠé›»å­ç…™è²©å”®
</div>
""", unsafe_allow_html=True)
                if "(1)" in text_result:
                    st.markdown("""
<div style="
    background-color: #fff3cd;
    color: #856404;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #ffeeba;
    font-size: 16px;
">
âš ï¸ <strong>é«˜é¢¨éšªç¶²ç«™</strong>ï¼šç¶²ç«™å¯èƒ½æ¶‰åŠé›»å­ç…™è²©å”®
</div>
""", unsafe_allow_html=True)
                else:
                    st.markdown("""
<div style="
    background-color: #d4edda;
    color: #155724;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #c3e6cb;
    font-size: 16px;
">
âœ… <strong>å®‰å…¨ç¶²ç«™</strong>ï¼šæœªåµæ¸¬å‡ºé«˜é¢¨éšªå…§å®¹
</div>
""", unsafe_allow_html=True)
    
        elif "æ‰¹é‡åˆ†æ" in mode:
            st.markdown("""
<style>
/* å°‡ file_uploader çš„æ¨™ç±¤èˆ‡ä¸Šå‚³æª”åéƒ½æ”¹ç‚ºç™½è‰² */
label, .stFileUploader label {
    color: white !important;
}

/* æª”åé¡¯ç¤ºå€å¡Šæ–‡å­—ï¼ˆå«å¤§å°ï¼‰ */
section[data-testid="stFileUploader"] div[aria-label] p {
    color: white !important;
}
</style>
""", unsafe_allow_html=True)


# æª”æ¡ˆä¸Šå‚³å…ƒä»¶

            uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ .txt æª”æ¡ˆï¼ˆæ¯è¡Œä¸€å€‹ç¶²å€ï¼‰", type=["txt"])
    
            if st.button("ğŸš€ é–‹å§‹æ‰¹æ¬¡åˆ†æ"):
                if uploaded_file is None:
                    st.markdown("""
<div style="
    background-color: #fff3cd;
    color: #856404;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #ffeeba;
    font-size: 16px;
">
âš ï¸ è«‹å…ˆä¸Šå‚³ .txt æª”æ¡ˆ
</div>
""", unsafe_allow_html=True)
                    return
    
                urls = [line.strip().decode("utf-8") for line in uploaded_file.readlines() if line]
                st.markdown(f"<h3 style='color:white;'>ğŸ“„ å…±æœ‰ {len(urls)} å€‹ç¶²å€å°‡é€²è¡Œåˆ†æ", unsafe_allow_html=True)

                high_risk_urls = []
    
                for idx, url in enumerate(urls, start=1):
                    st.markdown(f"<h3 style='color:white;'>\n ğŸ”— [{idx}/{len(urls)}] åˆ†æç¶²å€ï¼š{url}", unsafe_allow_html=True)

                    st.markdown("""
<style>
/* Modify spinner text color to match theme's primaryColor */
div[role="status"] > div > span {
    color: var(--primary-color) !important;
    font-weight: bold;
}
</style>
""", unsafe_allow_html=True)


                    with st.spinner("â³ æ­£åœ¨åˆ†æ..."):
                        text_content = crawl_all_text(url)
                        text_result = chain.invoke(text_content)
                        image_urls = crawl_images(url)
                        flagged_images = 0
    
                        # å·¦å³åˆ†å€ï¼šæ–‡å­— / åœ–åƒ
                        col1,  col2 = st.columns([5, 5])
    
                    with col1:
                        st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #1f77b4;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“„ æ–‡å­—åˆ†é¡çµæœ</h4>
        <pre style="white-space:pre-wrap;font-size:0.92rem;font-family:inherit;">
    {text_result}
        </pre>
    </div>
    """, unsafe_allow_html=True)
                    with col2:
                        if not image_urls:
                            st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
        <div style="font-size:0.9rem;"><b>(æœªæ‰¾åˆ°åœ–ç‰‡)</b></div>
    </div>
    """, unsafe_allow_html=True)
                        else:
                            sample_size = min(2, len(image_urls))
                            for img in random.sample(image_urls, sample_size):
                                img_result = classify_image(img, llm_image)
                                st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
        <img src="{img}" style="max-width:100%;border-radius:8px;margin-bottom:0.5rem;">
        <div style="font-size:0.9rem;"><b>åˆ†é¡çµæœï¼š</b>{img_result}</div>
    </div>
    """, unsafe_allow_html=True)
                                if "Warning" in img_result:
                                    flagged_images += 1
    
    
                    st.markdown("---")
                    # ç¶œåˆåˆ¤æ–·
                    if "(1)" in text_result and flagged_images > 0:
                        st.markdown("""
<div style="
    background-color: #fff3cd;
    color: #856404;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #ffeeba;
    font-size: 16px;
">
âš ï¸ <strong>é«˜é¢¨éšªç¶²ç«™</strong>ï¼šç¶²ç«™å¯èƒ½æ¶‰åŠé›»å­ç…™è²©å”®
</div>
""", unsafe_allow_html=True)
                        high_risk_urls.append(url)
                    if "(1)" in text_result:
                        st.markdown("""
<div style="
    background-color: #fff3cd;
    color: #856404;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #ffeeba;
    font-size: 16px;
">
âš ï¸ <strong>é«˜é¢¨éšªç¶²ç«™</strong>ï¼šç¶²ç«™å¯èƒ½æ¶‰åŠé›»å­ç…™è²©å”®
</div>
""", unsafe_allow_html=True)
                        high_risk_urls.append(url)

                    else:
                        st.markdown("""
<div style="
    background-color: #d4edda;
    color: #155724;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #c3e6cb;
    font-size: 16px;
">
âœ… <strong>å®‰å…¨ç¶²ç«™</strong>ï¼šæœªåµæ¸¬å‡ºé«˜é¢¨éšªå…§å®¹
</div>
""", unsafe_allow_html=True)
                st.markdown("---")
                st.markdown("<h3 style='color:white;'>ğŸ“‹ æ‰¹æ¬¡åˆ†æç¸½çµ</h3>", unsafe_allow_html=True)
                high_risk_urls = sorted(set(high_risk_urls))

                if high_risk_urls:
                    st.markdown(f"<h3 style='color:white;'>âš ï¸ å…±åµæ¸¬åˆ°é«˜é¢¨éšªç¶²å€ {len(high_risk_urls)} ç­†", unsafe_allow_html=True)
    
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰é«˜é¢¨éšªç¶²å€æ¸…å–®",
                        data="\n".join(high_risk_urls),
                        file_name="high_risk_urls.txt",
                        mime="text/plain"
                    )
                else:
                    st.markdown("""
<div style="
    background-color: #d4edda;
    color: #155724;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #c3e6cb;
    font-size: 16px;
">
âœ… æ‰€æœ‰ç¶²å€çš†æœªåµæ¸¬åˆ°é«˜é¢¨éšªå…§å®¹
</div>
""", unsafe_allow_html=True)
    
        elif "é—œéµå­—åˆ†æ" in mode:
            # è¼¸å…¥é—œéµå­—
            # è‡ªè¨‚æ–‡å­—é¡è‰²ç‚ºç™½è‰²
            st.markdown("""
            <style>
            /* èª¿æ•´ text_area èˆ‡ number_input çš„æ¨™ç±¤æ–‡å­—ç‚ºç™½è‰² */
            label, .stTextArea label, .stNumberInput label {
                color: white !important;
            }
            
            /* èª¿æ•´è¼¸å…¥æ¡†ä¸­æ–‡å­—ç‚ºç™½è‰²ï¼ŒèƒŒæ™¯ç‚ºæ·±è‰²ï¼ˆå¯è¦–éœ€æ±‚èª¿æ•´ï¼‰ */
            textarea, input[type="number"] {
                color: white !important;
                background-color: #1a1f2b !important;
            }
            </style>
            """, unsafe_allow_html=True)
            
            # UI å…ƒä»¶
            keywords_text = st.text_area(
                "ğŸ”¤ è«‹è¼¸å…¥æœå°‹é—œéµå­—ï¼ˆæ¯è¡Œä¸€å€‹ï¼‰",
                "vape\ne-juice\ne-cigarette\né›»å­ç…™"
            )
            
            limit = st.number_input("ğŸ”¢ æ¯å€‹é—œéµå­—æœ€å¤šæ“·å–å¹¾çµ„ç¶²å€ï¼Ÿ", min_value=1, max_value=50, value=10)
    
            if st.button("ğŸš€ åŸ·è¡Œ Google æœå°‹ä¸¦åˆ†æ"):
                if not keywords_text.strip():
                    st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥é—œéµå­—")
                    return
    
                keywords_list = [kw.strip() for kw in keywords_text.split("\n") if kw.strip()]
                st.markdown(f"""
<div style='
    background-color: #1e3a5f;
    color: white;
    padding: 1rem;
    border-left: 5px solid #3EB489;
    border-radius: 5px;
    font-size: 1rem;
'>
ğŸ” å°‡é‡å° <strong>{len(keywords_list)}</strong> å€‹é—œéµå­—ï¼Œå„æ“·å– <strong>{limit}</strong> çµ„æœå°‹çµæœ
</div>
""", unsafe_allow_html=True)
    
                all_urls = []
                for kw in keywords_list:
                    st.markdown(f"""
<h4 style='color:white;'>ğŸ” æœå°‹é—œéµå­—ï¼š<strong>{kw}</strong></h4>
""", unsafe_allow_html=True)
                    found = google_search(kw, count=limit)
                    all_urls.extend([url for url in found if url not in all_urls])
    
                st.markdown(f"""
<p style="color:white; font-size:1rem;">
ğŸ“¥ ç¸½å…±å–å¾— <strong>{len(all_urls)}</strong> å€‹åŸå§‹ç¶²å€
</p>
""", unsafe_allow_html=True)
    
                # éæ¿¾é»‘åå–®
                filtered_urls = [url for url in all_urls if not is_blacklisted_url(url)]
                st.markdown(f"""
<div style='
    background-color: #2e7d32;
    color: white;
    padding: 1rem;
    border-left: 5px solid #00c853;
    border-radius: 5px;
    font-size: 1rem;
'>
âœ… ç¶“ééæ¿¾å¾Œå‰©ä¸‹ <strong>{len(filtered_urls)}</strong> å€‹å¯ç–‘ç¶²å€
</div>
""", unsafe_allow_html=True)

    
                high_risk_urls = []
    
                for idx, url in enumerate(filtered_urls, start=1):
                    st.markdown(f"""
<hr style="border-top: 1px solid white;"/>
<h3 style="color:white;">
ğŸ”— [{idx}/{len(filtered_urls)}] åˆ†æç¶²å€ï¼š<a href="{url}" target="_blank" style="color:white; text-decoration:underline;">{url}</a>
</h3>
""", unsafe_allow_html=True)
    
                    with st.spinner("â³ æ­£åœ¨åˆ†æ..."):
                        text_content = crawl_all_text(url)
                        text_result = chain.invoke(text_content)
    
                        image_urls = crawl_images(url)
                        flagged_images = 0
    
                        # åˆ†å…©æ¬„é¡¯ç¤ºæ–‡å­—èˆ‡åœ–åƒ
                        col1,  col2 = st.columns([5,  5])
    
                    with col1:
                        st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #1f77b4;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“„ æ–‡å­—åˆ†é¡çµæœ</h4>
        <pre style="white-space:pre-wrap;font-size:0.92rem;font-family:inherit;">
    {text_result}
        </pre>
    </div>
    """, unsafe_allow_html=True)
                    with col2:
                        if not image_urls:
                            st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
        <div style="font-size:0.9rem;"><b>(æœªæ‰¾åˆ°åœ–ç‰‡)</b></div>
    </div>
    """, unsafe_allow_html=True)
                        else:
                            sample_size = min(2, len(image_urls))
                            for img in random.sample(image_urls, sample_size):
                                img_result = classify_image(img, llm_image)
                                st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
        <img src="{img}" style="max-width:100%;border-radius:8px;margin-bottom:0.5rem;">
        <div style="font-size:0.9rem;"><b>åˆ†é¡çµæœï¼š</b>{img_result}</div>
    </div>
    """, unsafe_allow_html=True)
                                if "Warning" in img_result:
                                    flagged_images += 1
    
    
    
                    
                    st.markdown("---")
                    # ç¶œåˆåˆ¤æ–·
                    if "(1)" in text_result and flagged_images > 0:
                        st.markdown("""
    <div style="
        background-color: #fff3cd;
        color: #856404;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #ffeeba;
        font-size: 16px;
    ">
    âš ï¸ <strong>é«˜é¢¨éšªç¶²ç«™</strong>ï¼šç¶²ç«™å¯èƒ½æ¶‰åŠé›»å­ç…™è²©å”®
    </div>
    """, unsafe_allow_html=True)
                        high_risk_urls.append(url)

                    if "(1)" in text_result:
                        st.markdown("""
    <div style="
        background-color: #fff3cd;
        color: #856404;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #ffeeba;
        font-size: 16px;
    ">
    âš ï¸ <strong>é«˜é¢¨éšªç¶²ç«™</strong>ï¼šç¶²ç«™å¯èƒ½æ¶‰åŠé›»å­ç…™è²©å”®
    </div>
    """, unsafe_allow_html=True)
                        high_risk_urls.append(url)

                    else:
                        st.markdown("""
    <div style="
        background-color: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #c3e6cb;
        font-size: 16px;
    ">
    âœ… <strong>å®‰å…¨ç¶²ç«™</strong>ï¼šæœªåµæ¸¬å‡ºé«˜é¢¨éšªå…§å®¹
    </div>
    """, unsafe_allow_html=True)
    
                # ç¸½çµèˆ‡ä¸‹è¼‰
                st.markdown("---")
                st.markdown("<h2 style='color:white;'>ğŸ“‹ åˆ†æç¸½çµ</h2>", unsafe_allow_html=True)
                high_risk_urls = sorted(set(high_risk_urls))

                if high_risk_urls:
                    st.warning(f"âš ï¸ åµæ¸¬åˆ°é«˜é¢¨éšªç¶²å€ï¼š{len(high_risk_urls)} ç­†")
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰é«˜é¢¨éšªç¶²å€æ¸…å–®",
                        data="\n".join(high_risk_urls),
                        file_name="google_high_risk_urls.txt",
                        mime="text/plain"
                    )
                else: 
                    st.markdown("""
    <div style="
        background-color: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #c3e6cb;
        font-size: 16px;
    ">
    âœ… æ‰€æœ‰æœå°‹çµæœå‡æœªåµæ¸¬åˆ°é«˜é¢¨éšªå…§å®¹
    </div>
    """, unsafe_allow_html=True)
        elif "ä»¥åœ–åˆ†æ" in mode:
        
            # åˆå§‹åŒ–ç‹€æ…‹æ——æ¨™
            if "download_finished" not in st.session_state:
                st.session_state.download_finished = False
            if "start_analysis" not in st.session_state:
                st.session_state.start_analysis = False
        
            # æ¨™é¡Œ + ä¸Šå‚³å€
            st.markdown("<h3 style='color:white;'>ğŸ“¸ ä¸Šå‚³åœ–ç‰‡ä»¥æœå°‹ç›¸ä¼¼ç¶²ç«™</h3>", unsafe_allow_html=True)
            st.markdown('<label style="color:white;font-size:1rem;">ğŸ“¤ è«‹ä¸Šå‚³åœ–ç‰‡ (jpg, jpeg, png)</label>', unsafe_allow_html=True)
        
            uploaded_files = st.file_uploader(
                "", type=["jpg", "jpeg", "png"], accept_multiple_files=True, label_visibility="collapsed"
            )
        
            # å¦‚æœæœ‰ä¸Šå‚³æ–°åœ–ç‰‡ â†’ é‡ç½®ç‹€æ…‹
            if uploaded_files:
                st.session_state.download_finished = False
                st.session_state.start_analysis = False
        
            # é¡¯ç¤ºã€Œé–‹å§‹åˆ†æã€æŒ‰éˆ•
            if st.button("ğŸš€ é–‹å§‹åˆ†æ"):
                if not uploaded_files:
                    st.markdown("""
                    <div style="
                        background-color: #fff3cd;
                        color: #856404;
                        padding: 1rem;
                        border-radius: 10px;
                        border: 1px solid #ffeeba;
                        font-size: 16px;
                    ">
                    âš ï¸ è«‹å…ˆä¸Šå‚³åœ–ç‰‡æª”æ¡ˆ (.jpg, .jpeg, .png)
                    </div>
                    """, unsafe_allow_html=True)
                    st.stop()
                else:
                    st.session_state.start_analysis = True
            else:
                st.stop()
        
            # ğŸ” åˆ†ææµç¨‹åªåœ¨ã€Œæœªé»æ“Šä¸‹è¼‰ã€+ã€Œå·²æŒ‰ä¸‹åˆ†æã€æ™‚åŸ·è¡Œ
            if uploaded_files and not st.session_state.download_finished and st.session_state.start_analysis:
                all_high_risk_urls = []
        
                for img_idx, uploaded_file in enumerate(uploaded_files, 1):
                    st.markdown(f"<h3 style='color:white;'>ğŸ“· åœ–ç‰‡ {img_idx}ï¼š{uploaded_file.name}</h3>", unsafe_allow_html=True)
                    st.image(uploaded_file, use_container_width=True)
        
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp_file:
                        tmp_file.write(uploaded_file.read())
                        tmp_path = tmp_file.name
        
                    try:
                        image_url = upload_image_to_imgbb(tmp_path)
                        st.markdown(f"""
                            <div style="background-color: #d4edda; color: #155724; padding: 1rem;
                                        border-radius: 10px; border: 1px solid #c3e6cb; font-size: 16px;">
                                âœ… åœ–ç‰‡ä¸Šå‚³æˆåŠŸï¼š<a href="{image_url}" target="_blank">{image_url}</a>
                            </div>
                        """, unsafe_allow_html=True)
        
                        with st.spinner("ğŸ” ä½¿ç”¨ Google æœå°‹ç›¸ä¼¼åœ–ç‰‡ä¸­..."):
                            urls = search_similar_images_via_serpapi(image_url)
        
                        st.markdown(f"<p style='color:white;'>ğŸ”— å…±å–å¾— {len(urls)} å€‹ç›¸ä¼¼ç¶²ç«™ç¶²å€</p>", unsafe_allow_html=True)
        
                        for url_idx, url in enumerate(urls, 1):
                            st.markdown(f"<h4 style='color:white;'>ğŸ”— [{url_idx}] åˆ†æç¶²å€ï¼š<a href='{url}' target='_blank'>{url}</a></h4>", unsafe_allow_html=True)
        
                            with st.spinner("â³ æ­£åœ¨åˆ†æç¶²ç«™å…§å®¹èˆ‡åœ–ç‰‡..."):
                                text_content = crawl_all_text(url)
                                text_result = chain.invoke(text_content)
                                image_urls = crawl_images(url)
                                flagged_images = 0
        
                                col1, col2 = st.columns([5, 5])
                                with col1:
                                    st.markdown(f"""
                                        <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;
                                                    border-radius:12px;border-left:6px solid #1f77b4;margin-bottom:1rem;">
                                            <h4 style="margin-bottom:0.8rem;">ğŸ“„ æ–‡å­—åˆ†é¡çµæœ</h4>
                                            <pre style="white-space:pre-wrap;font-size:0.92rem;font-family:inherit;">{text_result}</pre>
                                        </div>
                                    """, unsafe_allow_html=True)
        
                                with col2:
                                    if not image_urls:
                                        st.markdown("""
                                            <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;
                                                        border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
                                                <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
                                                <div style="font-size:0.9rem;"><b>(æœªæ‰¾åˆ°åœ–ç‰‡)</b></div>
                                            </div>
                                        """, unsafe_allow_html=True)
                                    else:
                                        for img in random.sample(image_urls, min(2, len(image_urls))):
                                            img_result = classify_image(img, llm_image)
                                            st.markdown(f"""
                                                <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;
                                                            border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
                                                    <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
                                                    <img src="{img}" style="max-width:100%;border-radius:8px;margin-bottom:0.5rem;">
                                                    <div style="font-size:0.9rem;"><b>åˆ†é¡çµæœï¼š</b>{img_result}</div>
                                                </div>
                                            """, unsafe_allow_html=True)
                                            if "Warning" in img_result:
                                                flagged_images += 1
        
                            if "(1)" in text_result or flagged_images > 0:
                                st.markdown("""
                                    <div style="background-color: #fff3cd; color: #856404; padding: 1rem;
                                                border-radius: 10px; border: 1px solid #ffeeba; font-size: 16px;">
                                        âš ï¸ <strong>é«˜é¢¨éšªç¶²ç«™</strong>ï¼šç¶²ç«™å¯èƒ½æ¶‰åŠé›»å­ç…™è²©å”®
                                    </div>
                                """, unsafe_allow_html=True)
                                all_high_risk_urls.append(url)
                            else:
                                st.markdown("""
                                    <div style="background-color: #d4edda; color: #155724; padding: 1rem;
                                                border-radius: 10px; border: 1px solid #c3e6cb; font-size: 16px;">
                                        âœ… <strong>å®‰å…¨ç¶²ç«™</strong>
                                    </div>
                                """, unsafe_allow_html=True)
        
                            st.markdown("---")
        
                    except Exception as e:
                        st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        
                # ğŸ“‹ åˆ†æç¸½çµ
                st.markdown("<h3 style='color:white;'>ğŸ“‹ æ‰€æœ‰åœ–ç‰‡åˆ†æç¸½çµ</h3>", unsafe_allow_html=True)
                unique_urls = sorted(set(all_high_risk_urls))
        
                if unique_urls:
                    st.markdown(f"""
                        <div style="background-color: #fff3cd; color: #856404; padding: 1rem;
                                    border-radius: 10px; border: 1px solid #ffeeba; font-size: 16px;">
                            âš ï¸ å…±åµæ¸¬åˆ°é«˜é¢¨éšªç¶²å€ {len(unique_urls)} ç­†
                        </div>
                    """, unsafe_allow_html=True)
        
                    if st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰é«˜é¢¨éšªç¶²å€æ¸…å–®",
                        data="\n".join(unique_urls),
                        file_name="imgsearch_high_risk_urls.txt",
                        mime="text/plain"
                    ):
                        st.session_state.download_finished = True
                        st.session_state.start_analysis = False  # é‡ç½®åˆ†æç‹€æ…‹
                        st.success("âœ… æª”æ¡ˆå·²ä¸‹è¼‰ï¼Œè«‹é‡æ–°ä¸Šå‚³åœ–ç‰‡é€²è¡Œä¸‹ä¸€è¼ªåˆ†æ")
                else:
                    st.markdown("""
                        <div style="background-color: #d4edda; color: #155724; padding: 1rem;
                                    border-radius: 10px; border: 1px solid #c3e6cb; font-size: 16px;">
                            âœ… æ‰€æœ‰æœå°‹çµæœçš†æœªåµæ¸¬å‡ºé«˜é¢¨éšªå…§å®¹
                        </div>
                    """, unsafe_allow_html=True)
        


if __name__ == "__main__":
    main()
