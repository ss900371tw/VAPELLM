import streamlit as st
import requests
import os
import shutil
import time
import random
import re
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from PIL import Image
from googleapiclient.discovery import build
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from urllib.parse import urljoin
import pickle
from googleapiclient.discovery import build
from PIL import Image
from io import BytesIO
from langchain_core.messages import AIMessage
from playwright.sync_api import sync_playwright
import sys
from urllib.parse import urlparse
from playwright.sync_api import sync_playwright
from urllib.parse import urlparse
import pickle
from bs4 import BeautifulSoup
import requests
import time
import sys
from bs4 import BeautifulSoup
import time
import undetected_chromedriver as uc

load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY","")



# -------------------- 2. Prompt --------------------
text_template = """
ä½œç‚ºä¸€ä½å°ˆæ¥­çš„é›»å­è¸äº¤æ˜“ç¶²ç«™åˆ†é¡å™¨ï¼Œ
ä½ å…·å‚™è¾¨è­˜ä¸‹åˆ— HTML å…§å®¹ä¸¦å°‡å…¶åˆ†é¡çš„èƒ½åŠ›ï¼š

è«‹ä¾æ“šä»¥ä¸‹å…©é¡é€²è¡Œåˆ†é¡ï¼š

(1) é›»å­è¸éŠ·å”®ç¶²ç«™

(2) éæ­¤é¡ç¶²ç«™

ç”±æ–¼ç”¢å“åç¨±ã€å“ç‰Œæˆ–æåŠæ–¹å¼ç„¡çª®ç„¡ç›¡ï¼Œè«‹å‹¿ä¾è³´ç‰¹å®šé—œéµå­—ï¼Œ
è€Œæ‡‰æ ¹æ“šé€šç”¨æŒ‡æ¨™åˆ¤æ–·ï¼Œç‰¹åˆ¥æ³¨æ„ä»¥ä¸‹å¹¾é»ï¼š

1ï¼‰ä½¿ç”¨æƒ…å¢ƒæˆ–å®£ç¨±å…§å®¹
ç•™æ„æ˜ç¤ºæˆ–æš—ç¤ºå…·ç²¾ç¥æ´»æ€§ã€è‡´å¹»æ•ˆæœã€æˆ–éæ³•ç”¨é€”çš„æè¿°ã€‚

è‹¥ç”¢å“æ¨™æ¦œæ”¹è®Šæƒ…ç·’ã€å¸¶ä¾†å¿«æ„Ÿã€å¼·åŠ›èˆ’å£“ç­‰éä¸€èˆ¬æ€§ç”¨é€”ï¼Œå¯èƒ½æš—ç¤ºå…¶å…·ç®¡åˆ¶å±¬æ€§ã€‚

2ï¼‰äº¤æ˜“æ€§ç·šç´¢
æåŠåƒ¹æ ¼ã€åƒæ˜¯ã€Œç§è¨Šæˆ‘ã€ã€ã€Œç¥•å¯†é…æ–¹ã€ã€ã€ŒåŠ  LINE è©³è«‡ã€ã€ã€Œéš±å¯†å‡ºè²¨ã€ç­‰æªè¾­ï¼Œ
å¯èƒ½èˆ‡éæ³•æˆ–å—é™ç”¢å“æœ‰é—œã€‚

è‹¥ç¶²ç«™æä¾›ï¼š

åŠ å…¥è³¼ç‰©è»Š

å¿«é€Ÿä¸‹å–®

ç”¢å“å‹éŒ„ç€è¦½

â†’ å³ä¾¿è¡¨é¢åˆæ³•ï¼Œä¹Ÿæ‡‰æé«˜è­¦è¦ºï¼Œå¯èƒ½å±¬æ–¼éæ³•è²©å”®ç¶²ç«™ã€‚

3ï¼‰æ³•å¾‹åˆ†é¡æˆ–è­¦ç¤ºè¨Šæ¯
æª¢æŸ¥æ˜¯å¦æœ‰é™åˆ¶è²©å”®ã€å¹´é½¡é©—è­‰ã€åƒ…é™æŒè­‰äººè³¼è²·ã€æˆ–åœ°å€æ€§éŠ·å”®é™åˆ¶ç­‰ã€‚

å°æ–¼æ¨¡ç³Šä¸æ¸…æˆ–è‡ªç›¸çŸ›ç›¾çš„è²æ˜ä¹Ÿè¦ä¿æŒè­¦æƒ•ã€‚

4ï¼‰ç”¢å“æˆ–æœå‹™é¡å‹
è‹¥ç”¢å“ç‚ºå·²çŸ¥ç®¡åˆ¶è—¥å“æˆ–è™•æ–¹è—¥å“ï¼ˆå¦‚ï¼šä½æ²›çœ ã€åœ°è¥¿æ³®ã€èŠ¬å¤ªå°¼ã€Kä»–å‘½ã€è´Šå®‰è«¾ã€æ›²é¦¬å¤šç­‰ï¼‰ï¼Œ
ä¸”æ­é…ä»¥ä¸‹åŠŸèƒ½ï¼š

åŠ å…¥è³¼ç‰©è»Š

å¿«é€Ÿè³¼è²·

SKU æˆ–å‹è™Ÿé¡¯ç¤º

æŸ¥è©¢åƒ¹æ ¼

æä¾›è³¼è²·èªªæ˜

â†’ ç„¡è«–è©²ç¶²ç«™çœ‹èµ·ä¾†å¤šéº¼å°ˆæ¥­ã€ç§‘å­¸æˆ–é†«ç™‚ï¼Œå‡æ‡‰åˆ¤å®šç‚º (1)

âš ï¸ æ³¨æ„ï¼šå°ˆæ¥­å¤–è§€èˆ‡ç§‘å­¸ç”¨èªç„¡æ³•æ©è“‹å…¶éŠ·å”®ç®¡åˆ¶ç‰©è³ªçš„äº‹å¯¦ã€‚

é›»å­è¸è£ç½®èˆ‡ç…™æ²¹ï¼ˆe-liquidï¼‰åŒæ¨£å±¬æ–¼ (1)ã€‚

è‹¥ç”¢å“ç‚ºéç®¡åˆ¶è£œå“ã€ä¸­è—¥æã€æˆ–ç„¡å®³è‰æœ¬ç”¢å“ï¼Œå‰‡å¯æ­¸ç‚º (2)ã€‚

5ï¼‰é—œéµæ€è€ƒ
ä¸è¦åªçœ‹å¤–è§€æˆ–å“ç‰ŒåŒ…è£ï¼Œæ›´é‡è¦çš„æ˜¯ç”¢å“å±¬æ€§èˆ‡æ˜¯å¦æä¾›ä¸‹å–®è³¼è²·æ©Ÿåˆ¶ã€‚

é‡é»åœ¨æ–¼ï¼š

å¯¦éš›è²©å”®çš„ç”¢å“æ˜¯å¦ç‚ºç®¡åˆ¶ç‰©è³ª

ç¶²ç«™æ˜¯å¦å…·æœ‰è³¼è²·åŠŸèƒ½æˆ–å¼•å°è³¼è²·è¡Œç‚º

6ï¼‰è³‡è¨Šæ€§æˆ–æ•™è‚²æ€§ç¶²ç«™
è‹¥ç¶²ç«™åƒ…æä¾›åƒè€ƒè³‡è¨Šï¼ˆå¦‚ï¼šç”¨é€”ã€å‰¯ä½œç”¨ã€äº¤äº’ä½œç”¨ã€åŠ‘é‡èªªæ˜ï¼‰ï¼Œ
ä¸”ç„¡æä¾›è³¼è²·ã€ä¸‹å–®ã€è¯çµ¡æ–¹å¼ç­‰åŠŸèƒ½ï¼Œæ‡‰æ­¸ç‚º (2)ã€‚

é€™é¡ç¶²ç«™åŒ…å«ï¼š

é†«å­¸ç™¾ç§‘

å¥åº·è³‡è¨Šå¹³å°

æ”¿åºœè³‡æº

è—¥å“è³‡æ–™åº«ï¼ˆå¦‚ï¼šdrugs.comã€WebMDã€NIHã€Mayo Clinicï¼‰

å³ä½¿æœ‰æåŠç®¡åˆ¶è—¥å“ï¼Œåªè¦ç„¡äº¤æ˜“ã€åƒ¹æ ¼ã€å‹è™Ÿæˆ–è¨‚è³¼è³‡è¨Šï¼Œå°±å±¬è³‡è¨Šæ€§ç”¨é€”ã€‚

ğŸ§  ç‰¹åˆ¥æ³¨æ„ï¼šè«‹å‹¿éŒ¯åˆ¤æ•™è‚²æ€§ç¶²ç«™ç‚ºè²©å”®ç¶²ç«™ã€‚

ğŸ”ã€å¾…åˆ†é¡ HTML å…§å®¹ã€‘ï¼š

{html}

ğŸ“‹ ç¶œåˆå ±å‘Šï¼š
æœ€çµ‚åˆ†é¡ï¼š(1) é›»å­è¸éŠ·å”®ç¶²ç«™  æˆ– (2) éæ­¤é¡ç¶²ç«™

å°è‡´æ­¤åˆ†é¡çš„é€šç”¨åˆ¤æ–·ä¾æ“šï¼ˆæ ¹æ“šä¸Šé¢ 1ï½6 æ¢ï¼‰

è‹¥æœ‰ä»»ä½•æ¨¡ç³Šè™•ï¼ˆä¾‹å¦‚çœ‹èµ·ä¾†å¾ˆå°ˆæ¥­ä½†å…¶å¯¦æœ‰è²©å”®è¡Œç‚ºï¼‰ï¼Œè«‹èªªæ˜ä½ çš„è™•ç†æ–¹å¼ã€‚


"""
prompt = PromptTemplate.from_template(template=text_template)

# -------------------- 3. çˆ¬å–ç¶²é æ–‡å­— --------------------


import subprocess
import os

# ç¢ºä¿ç€è¦½å™¨å·²å®‰è£ï¼ˆåƒ…é¦–æ¬¡éƒ¨ç½²æœƒè§¸ç™¼ï¼‰
def ensure_playwright_browser():
    chromium_path = os.path.expanduser("~/.cache/ms-playwright/chromium-*/chrome-linux/chrome")
    if not os.path.exists(chromium_path):
        try:
            print("âš™ï¸ å®‰è£ Playwright ç€è¦½å™¨ä¸­...")
            subprocess.run(["playwright", "install", "chromium"], check=True)
        except Exception as e:
            print("âŒ Playwright å®‰è£å¤±æ•—:", e)

ensure_playwright_browser()

from urllib.parse import urlparse
import pickle
import time
from bs4 import BeautifulSoup
import requests
from requests_html import HTMLSession

from playwright.sync_api import sync_playwright
from urllib.parse import urlparse
import pickle
from bs4 import BeautifulSoup
import requests
import time

from playwright.sync_api import sync_playwright
from urllib.parse import urlparse
import pickle
from bs4 import BeautifulSoup
import requests
import time



import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import pickle
import asyncio
from playwright.async_api import async_playwright


import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import pickle
import time
import undetected_chromedriver as uc  # âœ… ä¿ç•™é€™å€‹ï¼Œä¸ä½¿ç”¨ä¹Ÿä¸åˆªé™¤
import asyncio
from playwright.async_api import async_playwright


from bs4 import BeautifulSoup
import requests
import pickle
import time
from urllib.parse import urlparse
from playwright.sync_api import sync_playwright


import requests
from bs4 import BeautifulSoup
import pickle
import time
from urllib.parse import urlparse
from playwright.sync_api import sync_playwright
import undetected_chromedriver as uc

import os
import requests
import pickle
import time
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from playwright.sync_api import sync_playwright
import undetected_chromedriver as uc

from playwright.sync_api import sync_playwright
from urllib.parse import urlparse
import pickle
from bs4 import BeautifulSoup
import requests



import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup

import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup

from bs4 import BeautifulSoup
from urllib.parse import urlparse
import undetected_chromedriver as uc
import pickle
import time


import undetected_chromedriver as uc
import time
import pickle

import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import os

import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import os

# save_cookie.py
import asyncio
from playwright.async_api import async_playwright
import pickle
import os

from seleniumbase import SB
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import pickle
import time
from playwright.sync_api import sync_playwright

import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from playwright.sync_api import sync_playwright
import pickle
import os



def crawl_all_text(url: str, cookie_file: str = "cookies.pkl"):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        return soup.get_text(separator="\n", strip=True)[:50]

    except requests.exceptions.RequestException as e:
        if "403" in str(e):
            print("âš ï¸ HTTP 403 Forbidden - åˆ‡æ›ç‚º Playwright ç¹éé©—è­‰")

            try:
                with sync_playwright() as p:
                    browser = p.chromium.launch(headless=False)  # å»ºè­° debug æ™‚å…ˆç”¨é headless
                    context = browser.new_context()

                    parsed = urlparse(url)
                    base_url = f"{parsed.scheme}://{parsed.netloc}/"

                    # å…ˆé–‹é¦–é ï¼Œå»ºç«‹ domain context
                    page = context.new_page()
                    page.goto(base_url, timeout=30000)
                    time.sleep(3)

                    # è¼‰å…¥ cookiesï¼ˆå¦‚æœ‰ï¼‰
                    try:
                        with open(cookie_file, "rb") as f:
                            cookies = pickle.load(f)
                            for cookie in cookies:
                                if 'domain' not in cookie:
                                    cookie['domain'] = "." + parsed.hostname
                            context.add_cookies(cookies)
                    except Exception as err:
                        print("âš ï¸ Cookie è¼‰å…¥å¤±æ•—:", err)

                    # è·³è½‰åˆ°ç›®æ¨™é é¢
                    page.goto(url, timeout=30000)
                    time.sleep(5)
                    html = page.content()
                    browser.close()

                    soup = BeautifulSoup(html, "html.parser")
                    for tag in soup(["script", "style"]):
                        tag.decompose()

                    body_text = soup.get_text(separator="\n", strip=True)
                    if "é©—è­‰æ‚¨æ˜¯äººé¡" in body_text or "Enable JavaScript and cookies to continue" in body_text:
                        return "[âš ï¸ Cloudflare Verification Failed] Cookie å¯èƒ½å¤±æ•ˆæˆ–æœªæ­£ç¢ºé™„åŠ "

                    return body_text[:50]

            except Exception as e:
                return f"{url}"



# ---------------------------------------------------------------------------
# 4. çˆ¬å–ç¶²é çš„åœ–ç‰‡ URL
# ---------------------------------------------------------------------------


import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

def is_image_url(url: str) -> bool:
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                          "AppleWebKit/537.36 (KHTML, like Gecko) "
                          "Chrome/114.0.0.0 Safari/537.36"
        }
        resp = requests.head(url, headers=headers, timeout=5, allow_redirects=True)
        return resp.headers.get("Content-Type", "").lower().startswith("image/")
    except:
        return False

def normalize_src(src: str, base_url: str) -> str:
    if not src:
        return ""
    if src.startswith("//"):
        return "https:" + src
    return urljoin(base_url, src)

def crawl_images(url: str):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                          "AppleWebKit/537.36 (KHTML, like Gecko) "
                          "Chrome/114.0.0.0 Safari/537.36"
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        img_tags = soup.find_all("img")

        valid_extensions = {".jpg", ".jpeg", ".png", ".webp"}
        seen = set()
        img_urls = []

        for img in img_tags:
            src_candidates = [
                img.get("src"),
                img.get("data-src"),
                img.get("data-original"),
                img.get("data-image"),
                img.get("data-lazy"),
            ]

            for src in src_candidates:
                if not src:
                    continue
                full_url = normalize_src(src, url)
                if full_url in seen or len(full_url) < 10 or "base64" in full_url:
                    continue
                seen.add(full_url)

                lower_url = full_url.lower()
                if any(lower_url.endswith(ext) for ext in valid_extensions):
                    img_urls.append(full_url)
                    break
                elif is_image_url(full_url):
                    img_urls.append(full_url)
                    break

        return img_urls
    except Exception as e:
        print(f"[crawl_images error]: {e}")
        return []



# -------------------- 5. ä¸‹è¼‰åœ–ç‰‡ --------------------
def download_image(img_url, save_path="images"):
    if not os.path.exists(save_path):
        os.makedirs(save_path)

    img_name = os.path.join(save_path, os.path.basename(img_url.split("?")[0]))

    try:
        response = requests.get(img_url, stream=True, timeout=10)
        response.raise_for_status()
        with open(img_name, "wb") as out_file:
            shutil.copyfileobj(response.raw, out_file)
        return img_name
    except:
        return None


# -------------------- 6. åˆ†æåœ–ç‰‡ --------------------
def get_image_prompt(img_url: str) -> str:
    return f"""
è«‹æä¾›å¯¦éš›çš„åœ–ç‰‡æˆ–åœ–ç‰‡ç¶²å€ {img_url}ï¼Œæˆ‘æ‰èƒ½åˆ†æå…¶ä¸­æ˜¯å¦åŒ…å«ä»¥ä¸‹ä»»ä½•å—é™ç‰©å“æˆ–ç¬¦è™Ÿï¼š

é›»å­è¸è£ç½®æˆ–å…¶é›¶ä»¶

é›»å­ç…™å“ç‰Œæ¨™èªŒ

å¸ç…™ç…™éœ§æ•ˆæœ

ç®¡åˆ¶è—¥å“æˆ–å…¶ç”¨å…·

èˆ‡è—¥ç‰©æ–‡åŒ–ç›¸é—œçš„è¦–è¦ºå…ƒç´ 

æ¨å»£é›»å­è¸çš„è¡ŒéŠ·å…§å®¹ç­‰

ğŸ“· è«‹ä¸Šå‚³åœ–ç‰‡ï¼Œæˆ–æä¾›æœ‰æ•ˆçš„åœ–ç‰‡é€£çµï¼Œæˆ‘æœƒç«‹å³ç‚ºä½ åˆ¤å®šæ˜¯ï¼š

ğŸš¨ "Warning: Contains restricted items"

âœ… "Safe"

Image URL: {img_url}
"""

def classify_image(image_input, model):
    """
    image_input å¯ä»¥æ˜¯ï¼š
    - åœ–ç‰‡ç¶²å€ (str)
    - BytesIO åœ–ç‰‡è³‡æ–™ï¼ˆç›®å‰ä¸æ”¯æ´ï¼‰
    - æœ¬åœ°æª”æ¡ˆè·¯å¾‘ (str)
    model: ChatOpenAI é¡å‹æ¨¡å‹ï¼ˆå¦‚ gpt-4-vision-previewï¼‰
    """
    try:
        # å¦‚æœæ˜¯ç¶²å€
        if isinstance(image_input, str) and image_input.startswith("http"):
            message = HumanMessage(
                content=[
                    {"type": "text", "text": "è«‹åˆ¤æ–·é€™å¼µåœ–ç‰‡æ˜¯å¦åŒ…å«é›»å­è¸ã€æ¯’å“æˆ–ç›¸é—œç¬¦è™Ÿï¼Œå›å‚³ï¼šğŸš¨ Warning æˆ– âœ… Safe"},
                    {"type": "image_url", "image_url": {"url": image_input}},
                ]
            )
        elif isinstance(image_input, BytesIO):
            raise ValueError("LangChain ä¸æ”¯æ´ BytesIO åœ–ç‰‡è¼¸å…¥ï¼Œè«‹æ”¹ç”¨ OpenAI SDK")
        else:
            raise TypeError("ä¸æ”¯æ´çš„åœ–ç‰‡è¼¸å…¥é¡å‹")

        result = model.invoke([message])
        return result.content

    except Exception as e:
        return f"åœ–ç‰‡è®€å–æˆ–åˆ†æå¤±æ•—: {e}"

        
# -------------------- 7. Google Search --------------------
def google_search(query, count=10):
    api_key = os.getenv("GOOGLE_API_KEY")
    cx = os.getenv("GOOGLE_CX")
    if not api_key or not cx:
        print("âŒ GOOGLE_API_KEY æˆ– GOOGLE_CX æ²’æœ‰æ­£ç¢ºè¨­å®š")
        return []
    try:
        service = build("customsearch", "v1", developerKey=api_key)
        results = []
        fetched = 0
        while fetched < count:
            num = min(10, count - fetched)
            start = fetched + 1
            res = service.cse().list(q=query, cx=cx, num=num, start=start).execute()
            items = res.get("items", [])
            results.extend([item["link"] for item in items])
            fetched += len(items)
            if len(items) < num:
                break
        return results
    except Exception as e:
        print(f"âŒ Google æœå°‹éŒ¯èª¤ï¼š{e}")
        return []

# -------------------- 8. é»‘åå–® --------------------
blacklist_domains = [
    ".edu", ".gov", ".ac.", ".org", ".wiki", "usask.ca", "su.se", "article",
    "researchgate", "sciencedirect", "osf.io", "digitalcommons",
    "escholarship", "openai.com", "archive.org", "wiktionary",
    "urbandictionary", "dictionary", "bjc-r", "ecprice", "adamrose"
]
blacklist_keywords_in_url = [
    "slang", "street-names", "code-words", "download", "vocab", "wordlist",
    "unigrams", "passphrases", "pdf", "xml", "djvu.txt", "txt", "books",
    "raw/main", "viewcontent.cgi", "novel.pdf", "API/docs", "textfiles",
    "publications"
]

def is_blacklisted_url(url: str) -> bool:
    url_lower = url.lower()
    return any(domain in url_lower for domain in blacklist_domains) or \
           any(kw in url_lower for kw in blacklist_keywords_in_url)
    
# -------------------- 9. Streamlit ä¸»ç¨‹å¼ --------------------
def main():
    st.markdown("<h1 style='text-align:center;color:white;'>é›»å­è¸ç¶²ç«™åµæ¸¬ç³»çµ±</h1>", unsafe_allow_html=True)
    # ä½¿ç”¨ OpenAI GPT-4o æ¨¡å‹


    # èƒŒæ™¯æ¨£å¼èˆ‡ä¸»é¡Œæ–‡å­—
    st.markdown("""
    <style>
        .stApp {
            background-image: url("https://raw.githubusercontent.com/ss900371tw/VAPELLM/refs/heads/main/%E9%9B%BB%E5%AD%90%E8%8F%B8%E7%B6%B2%E7%AB%99%E5%81%B5%E6%B8%AC%E7%B3%BB%E7%B5%B1%20bg.png");
            background-size: cover;
            background-repeat: no-repeat;
            background-attachment: fixed;
        }
        h1, h2, h3 {
            color: #00FFFF;
        }
        .stButton > button {
            background-color: #3EB489;
            color: white;
            font-weight: bold;
            border-radius: 8px;
            padding: 0.5rem 1.2rem;
        }
    </style>
    """, unsafe_allow_html=True)

    st.markdown("""
    <p style='text-align:center; font-size: 24px; color: white;'>ğŸ§  åˆ©ç”¨ OpenAI + åœ–ç‰‡è¾¨è­˜ï¼Œè‡ªå‹•åˆ†é¡é›»å­ç…™ç›¸é—œç¶²ç«™</p>
    """, unsafe_allow_html=True)
    llm_text = ChatOpenAI(api_key=openai_api_key, model="gpt-4o", temperature=0)
    llm_image = ChatOpenAI(api_key=openai_api_key, model="gpt-4.1", temperature=0)
    parser = StrOutputParser()
    chain = prompt | llm_text | parser
    # åˆå§‹åŒ–
    if "selected_mode" not in st.session_state:
        st.session_state.selected_mode = None


                
    def render_card(icon, title, desc, key):
        selected = st.session_state.get("selected_mode") == title
        border = "4px solid #3EB489" if selected else "1px solid #999999"
        shadow = "0 0 20px #3EB489" if selected else "none"
        bg = "#0c1b2a" if selected else "#1a1f2b"
    
        with st.container():
            st.markdown(f"""
            <style>
            div#{key}_card {{
                background-color: {bg};
                color: white;
                border-radius: 16px;
                border: {border};
                box-shadow: {shadow};
                padding: 1.5rem;
                height: 320px;
                text-align: center;
                transition: all 0.2s ease;
                display: flex;
                flex-direction: column;
                justify-content: space-between;
            }}
            div#{key}_card:hover {{
                transform: scale(1.02);
                box-shadow: 0 0 25px #3EB489;
            }}
            div[data-testid="stButton"] > button#{key}_btn {{
                background-color: #3EB489;
                color: white;
                font-weight: bold;
                border: none;
                border-radius: 6px;
                font-size: 1rem;
                height: 40px;
                padding: 0 1.2rem;
            }}
            </style>
            """, unsafe_allow_html=True)
    
            # âœ… æŠŠæ‰€æœ‰å…§å®¹å¯«åœ¨é€™ä¸€å€‹ HTML block è£¡
            st.markdown(f"""
            <div id="{key}_card">
                <div style="font-size: 2rem;">{icon}</div>
                <div style="font-size: 1.2rem; font-weight: bold;">{title}</div>
                <div style="font-size: 0.9rem; color: #ccc;">{desc}</div>
                <div style="margin-top: 10px;">
            """, unsafe_allow_html=True)
    
            # âœ… Streamlit çš„æŒ‰éˆ•ä¹Ÿæ”¾åœ¨ div è£¡é¢
            if st.button("é¸æ“‡", key=f"{key}_btn"):
                st.session_state.selected_mode = title
                st.rerun()
    
            st.markdown("</div></div>", unsafe_allow_html=True)  # é—œé–‰å…©å±¤ div

    # æ¨¡å¼é¸æ“‡
    st.markdown("""
<style>
.banner-text {
    background-color: #0052cc;  /* æ·±è—è‰² */
    color: white;               /* ç™½å­— */
    font-size: 16px;
    font-weight: bold;
    text-align: center;
    padding: 10px;
    border-radius: 6px;
    margin: 10px 0px;
}
</style>

<div class="banner-text">
è«‹é¸æ“‡åˆ†ææ¨¡å¼
</div>
""", unsafe_allow_html=True)

    if "selected_mode" not in st.session_state:
        st.session_state.selected_mode = None

    # é›†ä¸­è™•ç†æŒ‰éˆ•äº‹ä»¶
    col1, col2, col3 = st.columns(3)
    with col1:
        render_card("ğŸ”", "å–®ä¸€ç¶²å€åˆ†æ", "åˆ†æå–®å€‹ç¶²ç«™çš„æ–‡å­—èˆ‡åœ–ç‰‡", key="single")
    with col2:
        render_card("ğŸ“‚", "æ‰¹é‡ç¶²å€åˆ†æ", "ä¸Šå‚³æ–‡å­—æª”ï¼Œåˆ†æå¤šå€‹ç¶²ç«™", key="batch")
    with col3:
        render_card("ğŸŒ", "é—œéµå­—æœå°‹åˆ†æ", "æ ¹æ“šé—œéµå­—è‡ªå‹•æœå°‹ç¶²ç«™", key="search")
    
    mode = st.session_state.get("selected_mode")
    
    if mode:    
        if "å–®ä¸€ç¶²å€åˆ†æ" in mode:
            # å»ºç«‹å·¦å³æ’åˆ—æ¬„ä½
            # è‡ªè¨‚æŒ‰éˆ•æ¨£å¼è®“å®ƒè²¼é½Š text_input é«˜åº¦
            
            # CSSï¼šç¾åŒ–æŒ‰éˆ•èˆ‡è¼¸å…¥æ¡†å®¹å™¨
            # --- è‡ªè¨‚æ¨£å¼ ---
            st.markdown("""
            <style>
            /* âœ… åªé‡å°å«æœ‰æŒ‰éˆ•çš„æ¬„ä½å…§éƒ¨ï¼Œå‚ç›´ç½®ä¸­ */
            div[data-testid="column"] div:has(button) {
                display: flex;
                align-items: center;
                justify-content: center;
            }
            
            /* âœ… è‡ªè¨‚æŒ‰éˆ•æ¨£å¼ */
            div[data-testid="column"] button {
                height: 40px;
                width: 60px;
                font-size: 20px;
                background-color: #3EB489;
                color: white;
                border-radius: 10px;
                border: 2px solid #ff5f5f;
                padding: 0;
            }
            </style>
            """, unsafe_allow_html=True)
            
            # --- è¡¨å–®è¼¸å…¥å€å¡Š ---
            with st.form("url_input_form"):
                col1, col2 = st.columns([6, 1])
                
                with col1:
                    url = st.text_input("", placeholder="è«‹è¼¸å…¥ç¶²å€ï¼š", label_visibility="collapsed")
                
                with col2:
                    submitted = st.form_submit_button("ç¢ºå®š")
            
                if submitted and url.strip():
                    st.success(f"âœ… ä½ è¼¸å…¥çš„ç¶²å€æ˜¯ï¼š{url}")
                elif submitted:
                    st.warning("âš ï¸ è«‹è¼¸å…¥æœ‰æ•ˆç¶²å€")
            

            # åˆ†æé‚è¼¯
            if go:
                if not url.strip():
                    st.warning("âš ï¸ è«‹è¼¸å…¥æœ‰æ•ˆç¶²å€")
                    return
    
                st.markdown(f"<h3 style='color:white;'>ğŸ” æ­£åœ¨åˆ†æï¼š<a href='{url}'>{url}</a></h3>", unsafe_allow_html=True)

                st.markdown("<p style='color:white;'>â³ æ­£åœ¨è®€å–ç¶²ç«™å…§å®¹èˆ‡åœ–ç‰‡...</p>", unsafe_allow_html=True)

                with st.spinner(" "): 
                    text_content = crawl_all_text(url)
                    text_result = chain.invoke(text_content)
    
                    image_urls = crawl_images(url)
                    flagged_images = 0
    
                    # åˆ†æˆå…©æ¬„é¡¯ç¤ºåˆ†æçµæœ
                    col1,  col2 = st.columns([5,  5])
    
                    with col1:
                        st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #1f77b4;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“„ æ–‡å­—åˆ†é¡çµæœ</h4>
        <pre style="white-space:pre-wrap;font-size:0.92rem;font-family:inherit;">
    {text_result} 
        </pre>
    </div>
    """, unsafe_allow_html=True)
                    with col2:
                        if not image_urls:
                            st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
        <div style="font-size:0.9rem;"><b>(æœªæ‰¾åˆ°åœ–ç‰‡)</b></div>
    </div>
    """, unsafe_allow_html=True)
                        else:
                            sample_size = min(2, len(image_urls))
                            for img in random.sample(image_urls, sample_size):
                                img_result = classify_image(img, llm_image)
                                st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
        <img src="{img}" style="max-width:100%;border-radius:8px;margin-bottom:0.5rem;">
        <div style="font-size:0.9rem;"><b>åˆ†é¡çµæœï¼š</b>{img_result}</div>
    </div>""", unsafe_allow_html=True)
                                if "Warning" in img_result:
                                    flagged_images += 1
    
    
    
                st.markdown("---")
                st.markdown("<h3 style='color:white;'>ğŸ“‹ ç¶œåˆçµè«–</h3>", unsafe_allow_html=True)
                if "(1)" in text_result and flagged_images > 0:
                    st.markdown("""
<div style="
    background-color: #fff3cd;
    color: #856404;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #ffeeba;
    font-size: 16px;
">
âš ï¸ <strong>é«˜é¢¨éšªç¶²ç«™</strong>ï¼šç¶²ç«™å¯èƒ½æ¶‰åŠé›»å­ç…™è²©å”®
</div>
""", unsafe_allow_html=True)
                if "(1)" in text_result:
                    st.markdown("""
<div style="
    background-color: #fff3cd;
    color: #856404;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #ffeeba;
    font-size: 16px;
">
âš ï¸ <strong>é«˜é¢¨éšªç¶²ç«™</strong>ï¼šç¶²ç«™å¯èƒ½æ¶‰åŠé›»å­ç…™è²©å”®
</div>
""", unsafe_allow_html=True)
                else:
                    st.markdown("""
<div style="
    background-color: #d4edda;
    color: #155724;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #c3e6cb;
    font-size: 16px;
">
âœ… <strong>å®‰å…¨ç¶²ç«™</strong>ï¼šæœªåµæ¸¬å‡ºé«˜é¢¨éšªå…§å®¹
</div>
""", unsafe_allow_html=True)
    
        elif "æ‰¹é‡ç¶²å€åˆ†æ" in mode:
            st.markdown("""
<style>
/* å°‡ file_uploader çš„æ¨™ç±¤èˆ‡ä¸Šå‚³æª”åéƒ½æ”¹ç‚ºç™½è‰² */
label, .stFileUploader label {
    color: white !important;
}

/* æª”åé¡¯ç¤ºå€å¡Šæ–‡å­—ï¼ˆå«å¤§å°ï¼‰ */
section[data-testid="stFileUploader"] div[aria-label] p {
    color: white !important;
}
</style>
""", unsafe_allow_html=True)


# æª”æ¡ˆä¸Šå‚³å…ƒä»¶

            uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ .txt æª”æ¡ˆï¼ˆæ¯è¡Œä¸€å€‹ç¶²å€ï¼‰", type=["txt"])
    
            if st.button("ğŸš€ é–‹å§‹æ‰¹æ¬¡åˆ†æ"):
                if uploaded_file is None:
                    st.warning("âš ï¸ è«‹å…ˆä¸Šå‚³ .txt æª”æ¡ˆ")
                    return
    
                urls = [line.strip().decode("utf-8") for line in uploaded_file.readlines() if line]
                st.markdown(f"<h3 style='color:white;'>ğŸ“„ å…±æœ‰ {len(urls)} å€‹ç¶²å€å°‡é€²è¡Œåˆ†æ", unsafe_allow_html=True)

                high_risk_urls = []
    
                for idx, url in enumerate(urls, start=1):
                    st.markdown(f"<h3 style='color:white;'>\n ğŸ”— [{idx}/{len(urls)}] åˆ†æç¶²å€ï¼š{url}", unsafe_allow_html=True)

                    st.markdown("""
<style>
/* Modify spinner text color to match theme's primaryColor */
div[role="status"] > div > span {
    color: var(--primary-color) !important;
    font-weight: bold;
}
</style>
""", unsafe_allow_html=True)


                    with st.spinner("â³ æ­£åœ¨åˆ†æ..."):
                        text_content = crawl_all_text(url)
                        text_result = chain.invoke(text_content)
                        image_urls = crawl_images(url)
                        flagged_images = 0
    
                        # å·¦å³åˆ†å€ï¼šæ–‡å­— / åœ–åƒ
                        col1,  col2 = st.columns([5, 5])
    
                    with col1:
                        st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #1f77b4;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“„ æ–‡å­—åˆ†é¡çµæœ</h4>
        <pre style="white-space:pre-wrap;font-size:0.92rem;font-family:inherit;">
    {text_result}
        </pre>
    </div>
    """, unsafe_allow_html=True)
                    with col2:
                        if not image_urls:
                            st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
        <div style="font-size:0.9rem;"><b>(æœªæ‰¾åˆ°åœ–ç‰‡)</b></div>
    </div>
    """, unsafe_allow_html=True)
                        else:
                            sample_size = min(2, len(image_urls))
                            for img in random.sample(image_urls, sample_size):
                                img_result = classify_image(img, llm_image)
                                st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
        <img src="{img}" style="max-width:100%;border-radius:8px;margin-bottom:0.5rem;">
        <div style="font-size:0.9rem;"><b>åˆ†é¡çµæœï¼š</b>{img_result}</div>
    </div>
    """, unsafe_allow_html=True)
                                if "Warning" in img_result:
                                    flagged_images += 1
    
    
                    st.markdown("---")
                    # ç¶œåˆåˆ¤æ–·
                    if "(1)" in text_result and flagged_images > 0:
                        st.markdown("""
<div style="
    background-color: #fff3cd;
    color: #856404;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #ffeeba;
    font-size: 16px;
">
âš ï¸ <strong>é«˜é¢¨éšªç¶²ç«™</strong>ï¼šç¶²ç«™å¯èƒ½æ¶‰åŠé›»å­ç…™è²©å”®
</div>
""", unsafe_allow_html=True)
                        high_risk_urls.append(url)
                    if "(1)" in text_result:
                        st.markdown("""
<div style="
    background-color: #fff3cd;
    color: #856404;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #ffeeba;
    font-size: 16px;
">
âš ï¸ <strong>é«˜é¢¨éšªç¶²ç«™</strong>ï¼šç¶²ç«™å¯èƒ½æ¶‰åŠé›»å­ç…™è²©å”®
</div>
""", unsafe_allow_html=True)
                        high_risk_urls.append(url)

                    else:
                        st.markdown("""
<div style="
    background-color: #d4edda;
    color: #155724;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #c3e6cb;
    font-size: 16px;
">
âœ… <strong>å®‰å…¨ç¶²ç«™</strong>ï¼šæœªåµæ¸¬å‡ºé«˜é¢¨éšªå…§å®¹
</div>
""", unsafe_allow_html=True)
                st.markdown("---")
                st.markdown("<h3 style='color:white;'>ğŸ“‹ æ‰¹æ¬¡åˆ†æç¸½çµ</h3>", unsafe_allow_html=True)
                high_risk_urls = sorted(set(high_risk_urls))

                if high_risk_urls:
                    st.markdown(f"<h3 style='color:white;'>âš ï¸ å…±åµæ¸¬åˆ°é«˜é¢¨éšªç¶²å€ {len(high_risk_urls)} ç­†", unsafe_allow_html=True)
    
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰é«˜é¢¨éšªç¶²å€æ¸…å–®",
                        data="\n".join(high_risk_urls),
                        file_name="high_risk_urls.txt",
                        mime="text/plain"
                    )
                else:
                    st.markdown("""
<div style="
    background-color: #d4edda;
    color: #155724;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid #c3e6cb;
    font-size: 16px;
">
âœ… æ‰€æœ‰ç¶²å€çš†æœªåµæ¸¬åˆ°é«˜é¢¨éšªå…§å®¹
</div>
""", unsafe_allow_html=True)
    
        else:
            # è¼¸å…¥é—œéµå­—
            # è‡ªè¨‚æ–‡å­—é¡è‰²ç‚ºç™½è‰²
            st.markdown("""
            <style>
            /* èª¿æ•´ text_area èˆ‡ number_input çš„æ¨™ç±¤æ–‡å­—ç‚ºç™½è‰² */
            label, .stTextArea label, .stNumberInput label {
                color: white !important;
            }
            
            /* èª¿æ•´è¼¸å…¥æ¡†ä¸­æ–‡å­—ç‚ºç™½è‰²ï¼ŒèƒŒæ™¯ç‚ºæ·±è‰²ï¼ˆå¯è¦–éœ€æ±‚èª¿æ•´ï¼‰ */
            textarea, input[type="number"] {
                color: white !important;
                background-color: #1a1f2b !important;
            }
            </style>
            """, unsafe_allow_html=True)
            
            # UI å…ƒä»¶
            keywords_text = st.text_area(
                "ğŸ”¤ è«‹è¼¸å…¥æœå°‹é—œéµå­—ï¼ˆæ¯è¡Œä¸€å€‹ï¼‰",
                "vape\ne-juice\ne-cigarette\né›»å­ç…™"
            )
            
            limit = st.number_input("ğŸ”¢ æ¯å€‹é—œéµå­—æœ€å¤šæ“·å–å¹¾çµ„ç¶²å€ï¼Ÿ", min_value=1, max_value=50, value=10)
    
            if st.button("ğŸš€ åŸ·è¡Œ Google æœå°‹ä¸¦åˆ†æ"):
                if not keywords_text.strip():
                    st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥é—œéµå­—")
                    return
    
                keywords_list = [kw.strip() for kw in keywords_text.split("\n") if kw.strip()]
                st.markdown(f"""
<div style='
    background-color: #1e3a5f;
    color: white;
    padding: 1rem;
    border-left: 5px solid #3EB489;
    border-radius: 5px;
    font-size: 1rem;
'>
ğŸ” å°‡é‡å° <strong>{len(keywords_list)}</strong> å€‹é—œéµå­—ï¼Œå„æ“·å– <strong>{limit}</strong> çµ„æœå°‹çµæœ
</div>
""", unsafe_allow_html=True)
    
                all_urls = []
                for kw in keywords_list:
                    st.markdown(f"""
<h4 style='color:white;'>ğŸ” æœå°‹é—œéµå­—ï¼š<strong>{kw}</strong></h4>
""", unsafe_allow_html=True)
                    found = google_search(kw, count=limit)
                    all_urls.extend([url for url in found if url not in all_urls])
    
                st.markdown(f"""
<p style="color:white; font-size:1rem;">
ğŸ“¥ ç¸½å…±å–å¾— <strong>{len(all_urls)}</strong> å€‹åŸå§‹ç¶²å€
</p>
""", unsafe_allow_html=True)
    
                # éæ¿¾é»‘åå–®
                filtered_urls = [url for url in all_urls if not is_blacklisted_url(url)]
                st.markdown(f"""
<div style='
    background-color: #2e7d32;
    color: white;
    padding: 1rem;
    border-left: 5px solid #00c853;
    border-radius: 5px;
    font-size: 1rem;
'>
âœ… ç¶“ééæ¿¾å¾Œå‰©ä¸‹ <strong>{len(filtered_urls)}</strong> å€‹å¯ç–‘ç¶²å€
</div>
""", unsafe_allow_html=True)

    
                high_risk_urls = []
    
                for idx, url in enumerate(filtered_urls, start=1):
                    st.markdown(f"""
<hr style="border-top: 1px solid white;"/>
<h3 style="color:white;">
ğŸ”— [{idx}/{len(filtered_urls)}] åˆ†æç¶²å€ï¼š<a href="{url}" target="_blank" style="color:white; text-decoration:underline;">{url}</a>
</h3>
""", unsafe_allow_html=True)
    
                    with st.spinner("â³ æ­£åœ¨åˆ†æ..."):
                        text_content = crawl_all_text(url)
                        text_result = chain.invoke(text_content)
    
                        image_urls = crawl_images(url)
                        flagged_images = 0
    
                        # åˆ†å…©æ¬„é¡¯ç¤ºæ–‡å­—èˆ‡åœ–åƒ
                        col1,  col2 = st.columns([5,  5])
    
                    with col1:
                        st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #1f77b4;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“„ æ–‡å­—åˆ†é¡çµæœ</h4>
        <pre style="white-space:pre-wrap;font-size:0.92rem;font-family:inherit;">
    {text_result}
        </pre>
    </div>
    """, unsafe_allow_html=True)
                    with col2:
                        if not image_urls:
                            st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
        <div style="font-size:0.9rem;"><b>(æœªæ‰¾åˆ°åœ–ç‰‡)</b></div>
    </div>
    """, unsafe_allow_html=True)
                        else:
                            sample_size = min(2, len(image_urls))
                            for img in random.sample(image_urls, sample_size):
                                img_result = classify_image(img, llm_image)
                                st.markdown(f"""
    <div style="background-color:#f7f9fc;padding:1.2rem 1.5rem;border-radius:12px;border-left:6px solid #ff7f0e;margin-bottom:1rem;">
        <h4 style="margin-bottom:0.8rem;">ğŸ“· åœ–åƒåˆ†æçµæœ</h4>
        <img src="{img}" style="max-width:100%;border-radius:8px;margin-bottom:0.5rem;">
        <div style="font-size:0.9rem;"><b>åˆ†é¡çµæœï¼š</b>{img_result}</div>
    </div>
    """, unsafe_allow_html=True)
                                if "Warning" in img_result:
                                    flagged_images += 1
    
    
    
                    
                    st.markdown("---")
                    # ç¶œåˆåˆ¤æ–·
                    if "(1)" in text_result and flagged_images > 0:
                        st.markdown("""
    <div style="
        background-color: #fff3cd;
        color: #856404;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #ffeeba;
        font-size: 16px;
    ">
    âš ï¸ <strong>é«˜é¢¨éšªç¶²ç«™</strong>ï¼šç¶²ç«™å¯èƒ½æ¶‰åŠé›»å­ç…™è²©å”®
    </div>
    """, unsafe_allow_html=True)
                        high_risk_urls.append(url)

                    if "(1)" in text_result:
                        st.markdown("""
    <div style="
        background-color: #fff3cd;
        color: #856404;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #ffeeba;
        font-size: 16px;
    ">
    âš ï¸ <strong>é«˜é¢¨éšªç¶²ç«™</strong>ï¼šç¶²ç«™å¯èƒ½æ¶‰åŠé›»å­ç…™è²©å”®
    </div>
    """, unsafe_allow_html=True)
                        high_risk_urls.append(url)

                    else:
                        st.markdown("""
    <div style="
        background-color: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #c3e6cb;
        font-size: 16px;
    ">
    âœ… <strong>å®‰å…¨ç¶²ç«™</strong>ï¼šæœªåµæ¸¬å‡ºé«˜é¢¨éšªå…§å®¹
    </div>
    """, unsafe_allow_html=True)
    
                # ç¸½çµèˆ‡ä¸‹è¼‰
                st.markdown("---")
                st.markdown("<h2 style='color:white;'>ğŸ“‹ åˆ†æç¸½çµ</h2>", unsafe_allow_html=True)
                high_risk_urls = sorted(set(high_risk_urls))

                if high_risk_urls:
                    st.warning(f"âš ï¸ åµæ¸¬åˆ°é«˜é¢¨éšªç¶²å€ï¼š{len(high_risk_urls)} ç­†")
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰é«˜é¢¨éšªç¶²å€æ¸…å–®",
                        data="\n".join(high_risk_urls),
                        file_name="google_high_risk_urls.txt",
                        mime="text/plain"
                    )
                else:
                    st.markdown("""
    <div style="
        background-color: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #c3e6cb;
        font-size: 16px;
    ">
    âœ… æ‰€æœ‰æœå°‹çµæœå‡æœªåµæ¸¬åˆ°é«˜é¢¨éšªå…§å®¹
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()


