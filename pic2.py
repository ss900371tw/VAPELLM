import streamlit as st
import requests
from bs4 import BeautifulSoup
import os
import shutil
from dotenv import load_dotenv
from PIL import Image
from langchain_core.output_parsers import StrOutputParser
from langchain_groq import ChatGroq
from langchain.prompts import PromptTemplate

# 1ï¸âƒ£ è¼‰å…¥ .env å–å¾— API Key
load_dotenv()
api_key = os.getenv("OLLAMA_API_KEY", "")

# 2ï¸âƒ£ å®šç¾© LLM åˆ†æ Prompt
template = """
As an expert classifier of e-cigarette and controlled-substance-selling websites,
you are equipped to analyze the following HTML and categorize it as either:
(1) an e-cigarette/controlled-substance-selling website,
(2) not such a website.

Because there are infinitely many potential products, brand names, or references, you will use
general indicators rather than item-specific keywords. In particular, consider the following:

1) **Context of Use or Claims**:
   - Look for explicit or subtle references to psychoactive, mind-altering, or illicit effects.
   - Check if the product or substance is described as mood-altering, giving a â€œhigh,â€ 
     relieving stress in an excessive/unusual manner, or otherwise hinting at controlled-substance properties.

2) **Transactional Cues**:
   - Mentions of pricing, â€œcontact me directly,â€ â€œsecret formula,â€ â€œLINE for details,â€ or 
     â€œdiscrete shippingâ€ may suggest illicit or regulated products.
   - Any site that allows **adding a controlled substance to cart**, submitting a **quick order**, or browsing a **product catalog** must be treated with caution, regardless of the overall appearance of legitimacy.

3) **Legal Categorization or Warnings**:
   - Check for restricted sale notes, age gating, disclaimers limiting sale to licensed buyers, or regional restrictions.
   - Be cautious of disclaimers that are vague or contradictory.

4) **Product or Service Type**:
   - **If a product is a known controlled substance or prescription medication** (e.g., Zopiclone, Diazepam, Fentanyl, Ketamine, Alprazolam, Tramadol, etc.), and is shown alongside features like:
     - "Add to Cart"
     - "Quick Order"
     - SKU or catalog number
     - Price lookup
     - Purchase instructions
     
     â†’ **You must classify it as (1)** â€” even if the site appears scientific, medical, or intended for research.

   - **âš ï¸ Scientific context or professional branding does NOT override the fact that the product is a controlled substance offered for sale.**

   - E-cigarette devices and e-liquids should also be classified as (1).

   - If the product is a non-controlled supplement, traditional medicine, or harmless herbal product, classify as (2).

5) **Critical Thought**:
   - Do NOT rely solely on appearance, branding, or stated purpose.
   - Prioritize the **actual product type** and **whether the website facilitates ordering** of a controlled substance.

6) Informational or Educational Context:
   - If the website only provides reference information about a drug (such as usage, side effects, interactions, dosages), and does not offer any purchase, order, or contact mechanism, it should be classified as (2).
   - These may include medical encyclopedias, health information platforms, government resources, or pharmacy guides (e.g., drugs.com, WebMD, NIH, or Mayo Clinic).
   - Even if controlled substances are discussed, the absence of ordering capability, pricing, product SKUs, or transactional elements indicates a non-commercial, informative nature.

ğŸ§  Be especially cautious not to misclassify informational reference sites as sellers.

---

HTML content to classify:
{html}

---

Comprehensive Report:
- Final classification: (1) or (2)
- What general indicators led to your conclusion (based on sections 1â€“6)?
- If there are any ambiguities (e.g., controlled substance on a professional-looking website), explain how you resolved them.
- **Emphasize the product type and orderability over context or appearance.**
"""
prompt = PromptTemplate.from_template(template=template)


# 3ï¸âƒ£ çˆ¬å–ç¶²é çš„æ–‡å­—å…§å®¹
def crawl_all_text(url: str):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        return soup.get_text(separator="\n", strip=True)[:1000]  # é™åˆ¶é•·åº¦ï¼Œé¿å…è¶…é LLM context window
    except requests.exceptions.RequestException as e:
        return f"Request failed: {e}"

# 4ï¸âƒ£ çˆ¬å–ç¶²é çš„åœ–ç‰‡ URL
def crawl_images(url: str):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        img_tags = soup.find_all("img")
        
        valid_extensions = {".jpg", ".jpeg", ".png", ".webp"}
        return [requests.compat.urljoin(url, img.get("src")) for img in img_tags if img.get("src") and any(img.get("src").lower().endswith(ext) for ext in valid_extensions)]
    except requests.exceptions.RequestException:
        return []

# 5ï¸âƒ£ ä¸‹è¼‰åœ–ç‰‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
def download_image(img_url, save_path="images"):
    if not os.path.exists(save_path):
        os.makedirs(save_path)
    
    img_name = os.path.join(save_path, os.path.basename(img_url.split("?")[0]))
    
    try:
        response = requests.get(img_url, stream=True, timeout=10)
        response.raise_for_status()
        
        with open(img_name, "wb") as out_file:
            shutil.copyfileobj(response.raw, out_file)
        return img_name
    except requests.exceptions.RequestException:
        return None

# 6ï¸âƒ£ ä½¿ç”¨ Vision AI åˆ†æåœ–ç‰‡
def classify_image(img_url, model):
    """
    ç›´æ¥ä½¿ç”¨åœ–ç‰‡ URL åˆ†æï¼Œå¦‚æœç„¡æ³•ç²å– URLï¼Œå‰‡è½‰ Base64 å‚³é
    """
    prompt = f"""
Analyze this image and determine whether it contains any of the following:
ğŸš¨ **If the image contains ANY of the following, classify it as "Warning: Contains restricted items"** ğŸš¨

- **E-cigarettes, vape pens, e-liquids, or any part of a vaping device** (including mouthpiece, tank, battery compartment, or any identifiable section of an e-cigarette).
- **Brand names or logos of vaping-related products** (even if not shown in promotional content).
- **Vape-related smoke effects** (clouds of vapor that indicate the presence of vaping activity).
- **Controlled substances** (such as marijuana, cocaine, heroin, pills, stimulants, or hallucinogens).
- **Paraphernalia associated with substance use** (rolling papers, bongs, syringes, grinders, etc.).
- **Psychoactive substances** (such as psychedelics, mushrooms, LSD, or DMT).
- **Visual elements commonly associated with drug culture** (e.g., "420" references, ğŸ symbols, psychedelic visuals).
- **Marketing materials promoting vaping products** (ads, discounts, promo banners, or promotional product displays).

âœ… **If NONE of the above are present, classify it as "Safe".**

Image URL: {img_url}
"""
    from langchain_core.messages import HumanMessage
    result = model.invoke([HumanMessage(content=prompt)])
    return result.content  # å›å‚³ LLM çµæœ

# 7ï¸âƒ£ Streamlit ä»‹é¢
def main():
    st.title("é›»å­è¸/ç®¡åˆ¶ç‰©å“ç¶²ç«™åˆ†é¡å™¨")

    # æä¾›é¸æ“‡æ¨¡å¼çš„é¸å–®
    mode = st.radio("é¸æ“‡åˆ†ææ¨¡å¼", ("å–®ä¸€ç¶²å€åˆ†æ", "æ‰¹é‡ç¶²å€åˆ†æ"))

    # åˆå§‹åŒ– LLM
    model = ChatGroq(api_key=api_key, model_name='llama3-8b-8192')
    parser = StrOutputParser()
    chain = prompt | model | parser

    if mode == "å–®ä¸€ç¶²å€åˆ†æ":
        # å–®ä¸€ç¶²å€è¼¸å…¥
        url = st.text_input("è«‹è¼¸å…¥ç¶²å€ï¼š")
        if st.button("é–‹å§‹åˆ†æ"):
            if not url.strip():
                st.warning("è«‹è¼¸å…¥æœ‰æ•ˆçš„ URLã€‚")
                return

            st.subheader(f"åˆ†æç¶²å€: {url}")

            # çˆ¬å–ç¶²é æ–‡å­—
            with st.spinner("æ–‡å­—åˆ†æä¸­..."):
                all_text = crawl_all_text(url)
                text_result = chain.invoke(all_text)

            st.write("ğŸ“„ æ–‡å­—åˆ†é¡çµæœï¼š")
            st.write(text_result)

            # çˆ¬å–åœ–ç‰‡
            st.write("ğŸ–¼ åœ–ç‰‡åˆ†é¡çµæœï¼š")
            image_urls = crawl_images(url)
            flagged_images = 0

            if not image_urls:
                st.write("æœªæ‰¾åˆ°åœ–ç‰‡")
            else:
                for img_url in image_urls[:10]:  # åªåˆ†æå‰ 5 å¼µåœ–ç‰‡
                    image_result = classify_image(img_url, model)
                    st.image(img_url, caption=f"åˆ†é¡çµæœ: {image_result}")
                    if "Warning" in image_result:
                        flagged_images += 1

            # ç¶œåˆåˆ¤æ–·
            if flagged_images == 0 and "(2)" in text_result:
                final_decision = "âœ… å®‰å…¨ç¶²ç«™"
            elif flagged_images >= 0 and "(1)" in text_result:
                final_decision = "âš ï¸ é«˜é¢¨éšªç¶²ç«™"
            st.subheader("ç¶œåˆåˆ†é¡çµæœï¼š")
            st.write(final_decision)

    elif mode == "æ‰¹é‡ç¶²å€åˆ†æ":
        uploaded_file = st.file_uploader("ä¸Šå‚³åŒ…å«å¯ç–‘ç¶²å€çš„ TXT æª”æ¡ˆ", type=["txt"])
        
        if st.button("é–‹å§‹åˆ†æ"):
            if uploaded_file is None:
                st.warning("è«‹ä¸Šå‚³ä¸€å€‹ .txt æª”æ¡ˆ")
                return

            # è®€å–æª”æ¡ˆå…§å®¹
            urls = [line.strip().decode("utf-8") for line in uploaded_file.readlines() if line]

            if not urls:
                st.warning("æª”æ¡ˆä¸­æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆç¶²å€")
                return

            st.write(f"ğŸ“Œ å…±è®€å– {len(urls)} å€‹ç¶²å€")

            high_risk_urls = []  # å­˜æ”¾é«˜é¢¨éšªç¶²å€

            for url in urls:
                st.subheader(f"åˆ†æç¶²å€: {url}")

                # çˆ¬å–ç¶²é æ–‡å­—
                with st.spinner("æ–‡å­—åˆ†æä¸­..."):
                    all_text = crawl_all_text(url)
                    text_result = chain.invoke(all_text)

                st.write("ğŸ“„ æ–‡å­—åˆ†é¡çµæœï¼š")
                st.write(text_result)

                # çˆ¬å–åœ–ç‰‡
                st.write("ğŸ–¼ åœ–ç‰‡åˆ†é¡çµæœï¼š")
                image_urls = crawl_images(url)
                flagged_images = 0

                if not image_urls:
                    st.write("æœªæ‰¾åˆ°åœ–ç‰‡")
                else:
                    for img_url in image_urls[:5]:  # åªåˆ†æå‰ 5 å¼µåœ–ç‰‡
                        image_result = classify_image(img_url, model)
                        st.image(img_url, caption=f"åˆ†é¡çµæœ: {image_result}")
                        if "Warning" in image_result:
                            flagged_images += 1

                if "(1)" in text_result and flagged_images >= 0:
                    high_risk_urls.append(url)

            # å„²å­˜é«˜é¢¨éšªç¶²å€
            if high_risk_urls:
                with open("high_risk_urls.txt", "w", encoding="utf-8") as file:
                    file.writelines(url + "\n" for url in high_risk_urls)
                st.success("âœ… é«˜é¢¨éšªç¶²å€å·²å­˜å…¥ `high_risk_urls.txt`")

if __name__ == "__main__":
    main()


























    